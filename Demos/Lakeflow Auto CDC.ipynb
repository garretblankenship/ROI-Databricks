{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d2ed096-5199-4ae1-87ce-3032cfa86c19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Lakeflow Auto CDC: Change Data Capture Made Easy üîÑ\n",
    "\n",
    "Welcome to the **Auto CDC** demo! This notebook teaches you how to automatically track and process data changes in your Lakeflow pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "## What you'll learn:\n",
    "\n",
    "* üìö **Part 1:** Understanding CDC concepts\n",
    "* üîç **Part 2:** How Auto CDC works\n",
    "* ü•â **Part 3:** Basic Auto CDC setup\n",
    "* üéØ **Part 4:** Advanced CDC features (SCD Type 1 & Type 2)\n",
    "* üèóÔ∏è **Part 5:** Handling deletes and complex scenarios\n",
    "* ‚úÖ **Part 6:** Best practices and monitoring\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "* Complete [Lakeflow Pipeline Fundamentals](#notebook/2846436383063456)\n",
    "* Complete [Lakeflow Expectations](#notebook/2846436383063443)\n",
    "* Understanding of streaming tables\n",
    "* Basic SQL knowledge\n",
    "\n",
    "---\n",
    "\n",
    "**Let's get started!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa6ba54e-2a36-481b-9ce4-2cb8a7631ccd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%undefined\n",
    "## Part 1: Understanding Change Data Capture (CDC) üìö\n",
    "\n",
    "Before using Auto CDC, let's understand what CDC is and why it matters.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d67a960e-755c-409b-94bd-55f2ff442410",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üîÑ What is Change Data Capture?\n",
    "\n",
    "**Definition:**\n",
    "* CDC tracks **changes** to data over time\n",
    "* Captures INSERT, UPDATE, and DELETE operations\n",
    "* Maintains history of how data evolves\n",
    "* Essential for data warehousing and analytics\n",
    "\n",
    "---\n",
    "\n",
    "### **The Problem Without CDC:**\n",
    "\n",
    "Imagine a customer table that gets updated daily:\n",
    "\n",
    "**Day 1:**\n",
    "```\n",
    "customer_id | name      | email              | status\n",
    "1           | Alice     | alice@email.com    | active\n",
    "2           | Bob       | bob@email.com      | active\n",
    "```\n",
    "\n",
    "**Day 2 (Bob's email changed):**\n",
    "```\n",
    "customer_id | name      | email              | status\n",
    "1           | Alice     | alice@email.com    | active\n",
    "2           | Bob       | bob_new@email.com  | active\n",
    "```\n",
    "\n",
    "**Problems:**\n",
    "* ‚ùå Lost Bob's old email address\n",
    "* ‚ùå Don't know WHEN it changed\n",
    "* ‚ùå Can't track history\n",
    "* ‚ùå Can't audit changes\n",
    "\n",
    "---\n",
    "\n",
    "### **The Solution With CDC:**\n",
    "\n",
    "CDC captures every change:\n",
    "\n",
    "```\n",
    "customer_id | name  | email              | status  | operation | timestamp\n",
    "1           | Alice | alice@email.com    | active  | INSERT    | 2026-01-20\n",
    "2           | Bob   | bob@email.com      | active  | INSERT    | 2026-01-20\n",
    "2           | Bob   | bob_new@email.com  | active  | UPDATE    | 2026-01-21\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "* ‚úÖ Complete history preserved\n",
    "* ‚úÖ Know what changed and when\n",
    "* ‚úÖ Can replay changes\n",
    "* ‚úÖ Full audit trail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11a085da-3a5e-4071-af2d-08187374d6ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üìù CDC Operation Types\n",
    "\n",
    "CDC tracks three types of operations:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. INSERT - New Records**\n",
    "\n",
    "**What it means:**\n",
    "* A new record was added\n",
    "* First time seeing this key\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "customer_id | name    | operation | timestamp\n",
    "3           | Charlie | INSERT    | 2026-01-22\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. UPDATE - Modified Records**\n",
    "\n",
    "**What it means:**\n",
    "* An existing record was changed\n",
    "* Key exists, but values changed\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "customer_id | name  | email              | operation | timestamp\n",
    "2           | Bob   | bob_new@email.com  | UPDATE    | 2026-01-21\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. DELETE - Removed Records**\n",
    "\n",
    "**What it means:**\n",
    "* A record was deleted from source\n",
    "* Mark as deleted (soft delete) or remove (hard delete)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "customer_id | operation | timestamp\n",
    "1           | DELETE    | 2026-01-23\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **How CDC Identifies Operations:**\n",
    "\n",
    "**Requires:**\n",
    "1. **Primary Key** - Unique identifier (e.g., `customer_id`)\n",
    "2. **Sequence Column** - Order of changes (e.g., `timestamp`, `version`)\n",
    "3. **Operation Column** (optional) - Explicit operation type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f2da556-2168-466d-a503-0078ff8afa0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üèõÔ∏è Slowly Changing Dimensions (SCD)\n",
    "\n",
    "CDC is often used to implement **Slowly Changing Dimensions** - a data warehousing pattern.\n",
    "\n",
    "---\n",
    "\n",
    "### **SCD Type 1 - Overwrite (No History)**\n",
    "\n",
    "**Behavior:**\n",
    "* Overwrites old values with new values\n",
    "* No history maintained\n",
    "* Only current state exists\n",
    "\n",
    "**Use case:** When history doesn't matter (e.g., fixing typos)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Before UPDATE:\n",
    "customer_id | name  | email\n",
    "2           | Bob   | bob@email.com\n",
    "\n",
    "After UPDATE:\n",
    "customer_id | name  | email\n",
    "2           | Bob   | bob_new@email.com  ‚Üê Old email gone\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **SCD Type 2 - Track History (Full History)**\n",
    "\n",
    "**Behavior:**\n",
    "* Keeps all historical versions\n",
    "* Adds new row for each change\n",
    "* Tracks validity periods\n",
    "\n",
    "**Use case:** When you need complete audit trail\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "customer_id | email              | valid_from  | valid_to    | is_current\n",
    "2           | bob@email.com      | 2026-01-20  | 2026-01-21  | false\n",
    "2           | bob_new@email.com  | 2026-01-21  | NULL        | true\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Lakeflow Auto CDC supports both SCD Type 1 and Type 2!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f7b4df6-df8e-44df-bf6e-4171fb39c490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Part 2: How Lakeflow Auto CDC Works üîç\n",
    "\n",
    "Lakeflow provides **automatic CDC processing** with the `APPLY CHANGES INTO` operation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9e86b47-dbad-40ca-9afd-28d9d9401f8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üÜï The New Auto CDC API\n",
    "\n",
    "**Important:** This demo uses the **new Auto CDC API** introduced in recent Databricks releases.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Differences from Legacy API:**\n",
    "\n",
    "**Old API (deprecated):**\n",
    "```python\n",
    "import dlt\n",
    "\n",
    "dlt.apply_changes(\n",
    "    target=\"customers\",\n",
    "    source=\"customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=\"timestamp\"\n",
    ")\n",
    "```\n",
    "\n",
    "**New API (current):**\n",
    "```python\n",
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dp.create_streaming_table(\"customers\")\n",
    "\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"customers\",\n",
    "    source=\"customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"timestamp\")\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **What Changed:**\n",
    "\n",
    "1. **Import statement:** `from pyspark import pipelines as dp` instead of `import dlt`\n",
    "2. **Decorators:** `@dp.view`, `@dp.table` instead of `@dlt.table`\n",
    "3. **Target creation:** Must explicitly create target with `dp.create_streaming_table()`\n",
    "4. **CDC function:** `dp.create_auto_cdc_flow()` instead of `dlt.apply_changes()`\n",
    "5. **Sequence column:** Use `col(\"column_name\")` function instead of string\n",
    "6. **SCD type:** String value `\"1\"` or `\"2\"` instead of integer\n",
    "7. **Delete condition:** Use `expr(\"condition\")` instead of string\n",
    "\n",
    "---\n",
    "\n",
    "**This new API is more explicit and aligns with Databricks' modern pipeline architecture.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ca984c7-d0dd-4ade-98db-92bfdedcda00",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Auto CDC Overview"
    }
   },
   "source": [
    "\n",
    "### ‚ö° What is Auto CDC?\n",
    "\n",
    "**Auto CDC** is a Lakeflow feature that automatically:\n",
    "* Processes change data from streaming sources\n",
    "* Applies INSERT, UPDATE, DELETE operations\n",
    "* Maintains SCD Type 1 or Type 2 tables\n",
    "* Handles out-of-order data\n",
    "* Deduplicates changes\n",
    "\n",
    "---\n",
    "\n",
    "### **Traditional CDC (Manual):**\n",
    "\n",
    "```python\n",
    "# Complex manual logic needed:\n",
    "# 1. Read changes\n",
    "# 2. Identify operation type\n",
    "# 3. Handle duplicates\n",
    "# 4. Merge with target table\n",
    "# 5. Track history (if SCD Type 2)\n",
    "# 6. Handle deletes\n",
    "# ... 100+ lines of code\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Auto CDC (Declarative):**\n",
    "\n",
    "```python\n",
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create target table\n",
    "dp.create_streaming_table(\"customers\")\n",
    "\n",
    "# Create Auto CDC flow\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"customers\",\n",
    "    source=\"customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"timestamp\")\n",
    ")\n",
    "```\n",
    "\n",
    "**That's it!** Lakeflow handles all the complexity.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Benefits:**\n",
    "\n",
    "* ‚úÖ **Simple** - Declarative syntax\n",
    "* ‚úÖ **Automatic** - Handles merges, deduplication\n",
    "* ‚úÖ **Reliable** - Handles out-of-order data\n",
    "* ‚úÖ **Flexible** - SCD Type 1 or Type 2\n",
    "* ‚úÖ **Performant** - Optimized for streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2b18276-098b-4adb-b03f-a077ff7a998a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Auto CDC Components"
    }
   },
   "source": [
    "\n",
    "### üß© Auto CDC Components\n",
    "\n",
    "Auto CDC requires these components:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Source View (Changes)**\n",
    "\n",
    "**What it is:**\n",
    "* View with change data (streaming or batch)\n",
    "* Contains INSERT, UPDATE, DELETE operations\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "@dp.view\n",
    "def customer_changes():\n",
    "    return spark.readStream.table(\"bronze_customer_changes\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Target Streaming Table (Current State)**\n",
    "\n",
    "**What it is:**\n",
    "* The table to apply changes to\n",
    "* Maintains current state (SCD Type 1) or history (SCD Type 2)\n",
    "* Must be created BEFORE the Auto CDC flow\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "dp.create_streaming_table(\"customers\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Auto CDC Flow**\n",
    "\n",
    "**What it is:**\n",
    "* The CDC processing logic\n",
    "* Defined using `dp.create_auto_cdc_flow()`\n",
    "\n",
    "**Required parameters:**\n",
    "* `target` - Target table name\n",
    "* `source` - Source view name\n",
    "* `keys` - Primary key columns (list)\n",
    "* `sequence_by` - Column to order changes (use `col()` function)\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"customers\",\n",
    "    source=\"customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"timestamp\")\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33a996e7-465d-4f20-adf4-b08cbe29b48e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Part 3: Basic Auto CDC Setup (SCD Type 1) ü•â\n",
    "\n",
    "Let's build our first Auto CDC pipeline with **SCD Type 1** (overwrite, no history).\n",
    "\n",
    "**Scenario:** Track customer information with latest values only.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e76f1916-818a-4640-bdff-1b3783da2509",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Bronze Layer - CDC Source"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# ============================================\n",
    "# BRONZE LAYER: Ingest CDC Changes\n",
    "# ============================================\n",
    "\n",
    "@dp.view\n",
    "def bronze_customer_changes():\n",
    "    \"\"\"\n",
    "    Ingest customer changes from source.\n",
    "    Each row represents a change event (INSERT, UPDATE, DELETE).\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.readStream\n",
    "        .table(\"samples.tpch.customer\")\n",
    "        .select(\n",
    "            col(\"c_custkey\").alias(\"customer_id\"),\n",
    "            col(\"c_name\").alias(\"customer_name\"),\n",
    "            col(\"c_address\").alias(\"address\"),\n",
    "            col(\"c_phone\").alias(\"phone\"),\n",
    "            col(\"c_mktsegment\").alias(\"market_segment\"),\n",
    "            current_timestamp().alias(\"change_timestamp\"),\n",
    "            lit(\"INSERT\").alias(\"operation\")  # Simulating CDC operation\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d4a7a02-a536-4435-a90d-d12c11df1fc5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Silver Layer - Apply Changes SCD Type 1"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SILVER LAYER: Apply CDC Changes (SCD Type 1)\n",
    "# ============================================\n",
    "\n",
    "# Create the target streaming table\n",
    "dp.create_streaming_table(\"silver_customers\")\n",
    "\n",
    "# Create Auto CDC flow to apply changes (SCD Type 1)\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_customers\",\n",
    "    source=\"bronze_customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"change_timestamp\"),\n",
    "    stored_as_scd_type=\"1\"  # SCD Type 1: Overwrite (no history)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "355fee50-e03c-42bd-b1f4-8aaadc38e132",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Understanding SCD Type 1 Code"
    }
   },
   "source": [
    "\n",
    "### üí° Understanding the Auto CDC Code\n",
    "\n",
    "**What we did:**\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Created Bronze Source View:**\n",
    "```python\n",
    "@dp.view\n",
    "def bronze_customer_changes():\n",
    "    return spark.readStream.table(\"samples.tpch.customer\")\n",
    "```\n",
    "* Ingests raw change data as a view\n",
    "* Each row is a change event\n",
    "* Includes operation type (INSERT, UPDATE, DELETE)\n",
    "* Uses `@dp.view` decorator from the new pipelines API\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Created Target Streaming Table:**\n",
    "```python\n",
    "dp.create_streaming_table(\"silver_customers\")\n",
    "```\n",
    "* Creates the target table for CDC changes\n",
    "* Must be created BEFORE the Auto CDC flow\n",
    "* Will contain the current state of data\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Created Auto CDC Flow:**\n",
    "```python\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_customers\",           # Target table to update\n",
    "    source=\"bronze_customer_changes\",    # Source view with changes\n",
    "    keys=[\"customer_id\"],                # Primary key\n",
    "    sequence_by=col(\"change_timestamp\"), # Order changes by timestamp\n",
    "    stored_as_scd_type=\"1\"               # SCD Type 1 (overwrite)\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Parameters Explained:**\n",
    "\n",
    "**`target`:**\n",
    "* Name of the target streaming table\n",
    "* Must be created first with `create_streaming_table()`\n",
    "* Contains current state of data\n",
    "\n",
    "**`source`:**\n",
    "* Name of the source view (created with `@dp.view`)\n",
    "* Contains change events\n",
    "* Must be a streaming source\n",
    "\n",
    "**`keys`:**\n",
    "* Primary key column(s) - list of column names\n",
    "* Used to identify which record to update\n",
    "* Can be composite key: `[\"customer_id\", \"order_id\"]`\n",
    "\n",
    "**`sequence_by`:**\n",
    "* Column to order changes (use `col()` function)\n",
    "* Ensures changes applied in correct order\n",
    "* Handles out-of-order data automatically\n",
    "\n",
    "**`stored_as_scd_type=\"1\"`:**\n",
    "* SCD Type 1: Overwrites old values\n",
    "* No history maintained\n",
    "* Only current state exists\n",
    "* Use `\"2\"` for SCD Type 2 (history tracking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fabadfd-db86-4d22-9a11-301ce858730c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üîÑ How SCD Type 1 Processes Changes\n",
    "\n",
    "**Example scenario:**\n",
    "\n",
    "---\n",
    "\n",
    "### **Initial State (Empty Table):**\n",
    "```\n",
    "silver_customers: (empty)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Change 1 - INSERT:**\n",
    "```\n",
    "customer_id | name    | email           | operation | timestamp\n",
    "1           | Alice   | alice@email.com | INSERT    | 10:00\n",
    "```\n",
    "\n",
    "**Result:**\n",
    "```\n",
    "silver_customers:\n",
    "customer_id | name    | email\n",
    "1           | Alice   | alice@email.com\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Change 2 - INSERT:**\n",
    "```\n",
    "customer_id | name  | email         | operation | timestamp\n",
    "2           | Bob   | bob@email.com | INSERT    | 10:01\n",
    "```\n",
    "\n",
    "**Result:**\n",
    "```\n",
    "silver_customers:\n",
    "customer_id | name    | email\n",
    "1           | Alice   | alice@email.com\n",
    "2           | Bob     | bob@email.com\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Change 3 - UPDATE:**\n",
    "```\n",
    "customer_id | name  | email             | operation | timestamp\n",
    "2           | Bob   | bob_new@email.com | UPDATE    | 10:02\n",
    "```\n",
    "\n",
    "**Result (SCD Type 1 - Overwrite):**\n",
    "```\n",
    "silver_customers:\n",
    "customer_id | name    | email\n",
    "1           | Alice   | alice@email.com\n",
    "2           | Bob     | bob_new@email.com  ‚Üê Updated (old value gone)\n",
    "```\n",
    "\n",
    "**Note:** Old email `bob@email.com` is lost - no history maintained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efbe849a-e647-4bc5-9f71-6c37f8144a46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üéØ Challenge 1: Create Auto CDC for Products\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Create an Auto CDC pipeline for product data using SCD Type 1.\n",
    "\n",
    "---\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. **Bronze table:** `bronze_product_changes`\n",
    "   * Ingest from `samples.tpch.part`\n",
    "   * Map columns:\n",
    "     * `p_partkey` ‚Üí `product_id`\n",
    "     * `p_name` ‚Üí `product_name`\n",
    "     * `p_brand` ‚Üí `brand`\n",
    "     * `p_size` ‚Üí `size`\n",
    "     * `p_retailprice` ‚Üí `price`\n",
    "   * Add `change_timestamp` (current timestamp)\n",
    "   * Add `operation` (set to \"INSERT\")\n",
    "\n",
    "2. **Streaming source:** `product_changes_stream`\n",
    "   * Read from `bronze_product_changes`\n",
    "\n",
    "3. **Apply CDC:**\n",
    "   * Target: `silver_products`\n",
    "   * Keys: `[\"product_id\"]`\n",
    "   * Sequence by: `change_timestamp`\n",
    "   * SCD Type 1\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code below:** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d3357fe-a3f1-422d-a6a3-088ff4ae0168",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Challenge 1 Solution Space"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CHALLENGE 1: Your solution here\n",
    "# ============================================\n",
    "\n",
    "# TODO: Create bronze_product_changes table\n",
    "\n",
    "\n",
    "# TODO: Create product_changes_stream table\n",
    "\n",
    "\n",
    "# TODO: Apply CDC changes to silver_products\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6011491-4079-4981-b653-b1fff5b4fe54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Part 4: Advanced CDC - SCD Type 2 (History Tracking) üéØ\n",
    "\n",
    "Now let's implement **SCD Type 2** to maintain complete history of changes.\n",
    "\n",
    "**Scenario:** Track customer information with full audit trail.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1edb496-ee25-49a2-b6aa-c6547a547b34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üìú SCD Type 2 - History Tracking\n",
    "\n",
    "**What is SCD Type 2?**\n",
    "* Maintains **complete history** of all changes\n",
    "* Creates **new row** for each change\n",
    "* Tracks **validity periods** for each version\n",
    "* Marks **current** vs **historical** records\n",
    "\n",
    "---\n",
    "\n",
    "### **SCD Type 2 Columns:**\n",
    "\n",
    "Auto CDC automatically adds these columns:\n",
    "\n",
    "**`__START_AT`:**\n",
    "* When this version became valid\n",
    "* Timestamp of the change\n",
    "\n",
    "**`__END_AT`:**\n",
    "* When this version became invalid\n",
    "* NULL for current version\n",
    "\n",
    "**`__CURRENT`:**\n",
    "* Boolean flag\n",
    "* TRUE for current version\n",
    "* FALSE for historical versions\n",
    "\n",
    "---\n",
    "\n",
    "### **Example:**\n",
    "\n",
    "**Changes:**\n",
    "```\n",
    "Timestamp | customer_id | name  | email\n",
    "10:00     | 2           | Bob   | bob@email.com\n",
    "10:05     | 2           | Bob   | bob_new@email.com\n",
    "10:10     | 2           | Bob   | bob_final@email.com\n",
    "```\n",
    "\n",
    "**Result (SCD Type 2):**\n",
    "```\n",
    "customer_id | name | email              | __START_AT | __END_AT | __CURRENT\n",
    "2           | Bob  | bob@email.com      | 10:00      | 10:05    | false\n",
    "2           | Bob  | bob_new@email.com  | 10:05      | 10:10    | false\n",
    "2           | Bob  | bob_final@email.com| 10:10      | NULL     | true\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "* ‚úÖ Complete audit trail\n",
    "* ‚úÖ Can query historical state\n",
    "* ‚úÖ Know exactly when changes occurred\n",
    "* ‚úÖ Can rollback to any point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e3fcd09-ad29-4e5b-a874-d67d47e5ba58",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SCD Type 2 Implementation"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# SILVER LAYER: Apply CDC Changes (SCD Type 2)\n",
    "# ============================================\n",
    "\n",
    "# Create the target streaming table for SCD Type 2\n",
    "dp.create_streaming_table(\"silver_customers_history\")\n",
    "\n",
    "# Create Auto CDC flow with SCD Type 2 (history tracking)\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_customers_history\",\n",
    "    source=\"bronze_customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"change_timestamp\"),\n",
    "    stored_as_scd_type=\"2\"  # SCD Type 2: Track history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7648c4a-ae26-47ab-b60a-b6e59b68ef57",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "SCD Type 2 Code Explanation"
    }
   },
   "source": [
    "\n",
    "### üí° SCD Type 2 - What Changed?\n",
    "\n",
    "**The only difference from SCD Type 1:**\n",
    "\n",
    "```python\n",
    "stored_as_scd_type=\"2\"  # Changed from \"1\" to \"2\"\n",
    "```\n",
    "\n",
    "**That's it!** Auto CDC handles all the complexity:\n",
    "\n",
    "---\n",
    "\n",
    "### **What Auto CDC Does Automatically:**\n",
    "\n",
    "1. **Creates history rows:**\n",
    "   * New row for each change\n",
    "   * Preserves all historical versions\n",
    "\n",
    "2. **Adds tracking columns:**\n",
    "   * `__START_AT` - When version became valid\n",
    "   * `__END_AT` - When version became invalid\n",
    "   * `__CURRENT` - Is this the current version?\n",
    "\n",
    "3. **Manages validity periods:**\n",
    "   * Sets `__END_AT` on old versions\n",
    "   * Sets `__END_AT = NULL` on current version\n",
    "   * Updates `__CURRENT` flag\n",
    "\n",
    "4. **Handles out-of-order data:**\n",
    "   * Uses `sequence_by` to order changes\n",
    "   * Correctly updates validity periods\n",
    "\n",
    "---\n",
    "\n",
    "### **Querying SCD Type 2 Tables:**\n",
    "\n",
    "**Get current records only:**\n",
    "```sql\n",
    "SELECT * FROM silver_customers_history\n",
    "WHERE __CURRENT = true\n",
    "```\n",
    "\n",
    "**Get all history:**\n",
    "```sql\n",
    "SELECT * FROM silver_customers_history\n",
    "ORDER BY customer_id, __START_AT\n",
    "```\n",
    "\n",
    "**Get state at specific time:**\n",
    "```sql\n",
    "SELECT * FROM silver_customers_history\n",
    "WHERE __START_AT <= '2026-01-25 10:00:00'\n",
    "  AND (__END_AT > '2026-01-25 10:00:00' OR __END_AT IS NULL)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67c7dac0-167a-4892-a8f8-b98225a4c006",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üéØ Challenge 2: Create SCD Type 2 for Suppliers\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Create an Auto CDC pipeline for supplier data with full history tracking (SCD Type 2).\n",
    "\n",
    "---\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. **Bronze table:** `bronze_supplier_changes`\n",
    "   * Ingest from `samples.tpch.supplier`\n",
    "   * Map columns:\n",
    "     * `s_suppkey` ‚Üí `supplier_id`\n",
    "     * `s_name` ‚Üí `supplier_name`\n",
    "     * `s_address` ‚Üí `address`\n",
    "     * `s_phone` ‚Üí `phone`\n",
    "     * `s_acctbal` ‚Üí `account_balance`\n",
    "   * Add `change_timestamp` (current timestamp)\n",
    "   * Add `operation` (set to \"INSERT\")\n",
    "\n",
    "2. **Streaming source:** `supplier_changes_stream`\n",
    "   * Read from `bronze_supplier_changes`\n",
    "\n",
    "3. **Apply CDC with SCD Type 2:**\n",
    "   * Target: `silver_suppliers_history`\n",
    "   * Keys: `[\"supplier_id\"]`\n",
    "   * Sequence by: `change_timestamp`\n",
    "   * SCD Type 2 (history tracking)\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code below:** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb58b454-42d5-4af6-aa8c-82e4023b70fe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Challenge 2 Solution Space"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CHALLENGE 2: Your solution here\n",
    "# ============================================\n",
    "\n",
    "# TODO: Create bronze_supplier_changes table\n",
    "\n",
    "\n",
    "# TODO: Create supplier_changes_stream table\n",
    "\n",
    "\n",
    "# TODO: Apply CDC changes with SCD Type 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b4324fc-7c3d-47b2-afe0-03accb0f5232",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Part 5: Handling Deletes and Complex Scenarios üèóÔ∏è\n",
    "\n",
    "Let's explore advanced CDC features: handling deletes, column tracking, and filtering.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2cd9b11-7682-4ccc-9343-a76c8497e872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üóëÔ∏è Handling DELETE Operations\n",
    "\n",
    "Auto CDC can handle DELETE operations in two ways:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Soft Delete (Default for SCD Type 2)**\n",
    "\n",
    "**Behavior:**\n",
    "* Marks record as deleted\n",
    "* Keeps the record in the table\n",
    "* Sets `__END_AT` timestamp\n",
    "* Sets `__CURRENT = false`\n",
    "\n",
    "**Use case:** Maintain complete audit trail including deletions\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Before DELETE:\n",
    "customer_id | name  | __START_AT | __END_AT | __CURRENT\n",
    "2           | Bob   | 10:00      | NULL     | true\n",
    "\n",
    "After DELETE:\n",
    "customer_id | name  | __START_AT | __END_AT | __CURRENT\n",
    "2           | Bob   | 10:00      | 10:15    | false\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Hard Delete (Optional)**\n",
    "\n",
    "**Behavior:**\n",
    "* Physically removes the record\n",
    "* No trace left in table\n",
    "\n",
    "**Use case:** Compliance (GDPR), data retention policies\n",
    "\n",
    "**Configuration:**\n",
    "```python\n",
    "dlt.apply_changes(\n",
    "    target=\"customers\",\n",
    "    source=\"customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=\"timestamp\",\n",
    "    apply_as_deletes=\"operation = 'DELETE'\",  # Specify delete condition\n",
    "    apply_as_truncates=\"operation = 'TRUNCATE'\"  # Optional: truncate condition\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Identifying Deletes:**\n",
    "\n",
    "Auto CDC needs to know which records are deletes:\n",
    "\n",
    "**Option 1: Operation column**\n",
    "```python\n",
    "apply_as_deletes=\"operation = 'DELETE'\"\n",
    "```\n",
    "\n",
    "**Option 2: Deleted flag**\n",
    "```python\n",
    "apply_as_deletes=\"is_deleted = true\"\n",
    "```\n",
    "\n",
    "**Option 3: Null values**\n",
    "```python\n",
    "apply_as_deletes=\"customer_name IS NULL\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c85a65fb-1086-4485-ab15-b1d19a6679c0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Delete Example Implementation"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CDC with DELETE Handling\n",
    "# ============================================\n",
    "\n",
    "# Bronze layer with delete operations\n",
    "@dp.view\n",
    "def bronze_customer_changes_with_deletes():\n",
    "    \"\"\"\n",
    "    Simulating CDC feed with INSERT, UPDATE, and DELETE operations.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.readStream\n",
    "        .table(\"samples.tpch.customer\")\n",
    "        .select(\n",
    "            col(\"c_custkey\").alias(\"customer_id\"),\n",
    "            col(\"c_name\").alias(\"customer_name\"),\n",
    "            col(\"c_address\").alias(\"address\"),\n",
    "            col(\"c_phone\").alias(\"phone\"),\n",
    "            current_timestamp().alias(\"change_timestamp\"),\n",
    "            # Randomly mark some records as deleted for demo\n",
    "            when(col(\"c_custkey\") % 100 == 0, lit(\"DELETE\"))\n",
    "            .otherwise(lit(\"INSERT\"))\n",
    "            .alias(\"operation\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create target streaming table\n",
    "dp.create_streaming_table(\"silver_customers_with_deletes\")\n",
    "\n",
    "# Apply changes with delete handling\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_customers_with_deletes\",\n",
    "    source=\"bronze_customer_changes_with_deletes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"change_timestamp\"),\n",
    "    stored_as_scd_type=\"2\",\n",
    "    apply_as_deletes=expr(\"operation = 'DELETE'\")  # Handle DELETE operations\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06bbae2b-dbf6-4cd2-a502-8f84ec7309dd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Column Tracking and Filtering"
    }
   },
   "source": [
    "\n",
    "### üìä Advanced Features: Column Tracking and Filtering\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Track History on Specific Columns**\n",
    "\n",
    "You can exclude columns from history tracking (SCD Type 2):\n",
    "\n",
    "```python\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"customers\",\n",
    "    source=\"customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"timestamp\"),\n",
    "    stored_as_scd_type=\"2\",\n",
    "    track_history_except_column_list=[\"last_login\", \"login_count\"]  # Don't track these\n",
    ")\n",
    "```\n",
    "\n",
    "**Use case:**\n",
    "* Ignore changes to non-critical columns\n",
    "* Reduce storage for SCD Type 2\n",
    "* Focus on important business attributes\n",
    "\n",
    "**Example:**\n",
    "* Track changes to `email`, `phone`, `address`\n",
    "* Ignore changes to `last_login`, `login_count` (frequently changing, not important)\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Exclude Columns from Target**\n",
    "\n",
    "Exclude columns from the target table:\n",
    "\n",
    "```python\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"customers\",\n",
    "    source=\"customer_changes\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"timestamp\"),\n",
    "    except_column_list=[\"operation\", \"source_system\"]  # Don't include these\n",
    ")\n",
    "```\n",
    "\n",
    "**Use case:**\n",
    "* Remove CDC metadata columns\n",
    "* Exclude technical columns\n",
    "* Keep target table clean\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Filter Source Data**\n",
    "\n",
    "Apply filters before CDC processing:\n",
    "\n",
    "```python\n",
    "@dp.view\n",
    "def customer_changes_filtered():\n",
    "    return (\n",
    "        spark.readStream.table(\"bronze_customer_changes\")\n",
    "        .filter(col(\"country\") == \"USA\")  # Only process USA customers\n",
    "    )\n",
    "\n",
    "dp.create_streaming_table(\"silver_customers_usa\")\n",
    "\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_customers_usa\",\n",
    "    source=\"customer_changes_filtered\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"timestamp\")\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddf4e045-acd2-4aa6-830c-4db30629ce16",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Composite Keys Example"
    }
   },
   "source": [
    "\n",
    "### üîë Composite Keys (Multiple Columns)\n",
    "\n",
    "Some tables require multiple columns as primary key:\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: Order Line Items**\n",
    "\n",
    "**Scenario:**\n",
    "* Each order has multiple line items\n",
    "* Primary key: `order_id` + `line_number`\n",
    "\n",
    "**Implementation:**\n",
    "```python\n",
    "@dp.view\n",
    "def order_line_changes():\n",
    "    return (\n",
    "        spark.readStream\n",
    "        .table(\"samples.tpch.lineitem\")\n",
    "        .select(\n",
    "            col(\"l_orderkey\").alias(\"order_id\"),\n",
    "            col(\"l_linenumber\").alias(\"line_number\"),\n",
    "            col(\"l_partkey\").alias(\"product_id\"),\n",
    "            col(\"l_quantity\").alias(\"quantity\"),\n",
    "            col(\"l_extendedprice\").alias(\"price\"),\n",
    "            current_timestamp().alias(\"change_timestamp\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create target table\n",
    "dp.create_streaming_table(\"silver_order_lines\")\n",
    "\n",
    "# Create Auto CDC flow with composite key\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_order_lines\",\n",
    "    source=\"order_line_changes\",\n",
    "    keys=[\"order_id\", \"line_number\"],  # Composite key\n",
    "    sequence_by=col(\"change_timestamp\"),\n",
    "    stored_as_scd_type=\"1\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Key points:**\n",
    "* `keys` accepts list of multiple columns\n",
    "* All key columns must be present in source\n",
    "* Combination must be unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3724cbcd-7791-4d13-a427-bc7205c9c8a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üéØ Challenge 3: Advanced CDC with Composite Keys\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Create an Auto CDC pipeline for order line items with composite keys and delete handling.\n",
    "\n",
    "---\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. **Bronze table:** `bronze_orderline_changes`\n",
    "   * Ingest from `samples.tpch.lineitem`\n",
    "   * Map columns:\n",
    "     * `l_orderkey` ‚Üí `order_id`\n",
    "     * `l_linenumber` ‚Üí `line_number`\n",
    "     * `l_partkey` ‚Üí `product_id`\n",
    "     * `l_quantity` ‚Üí `quantity`\n",
    "     * `l_extendedprice` ‚Üí `extended_price`\n",
    "     * `l_linestatus` ‚Üí `status`\n",
    "   * Add `change_timestamp` (current timestamp)\n",
    "   * Add `operation` column:\n",
    "     * Set to \"DELETE\" if `l_linestatus = 'F'` (finished)\n",
    "     * Otherwise set to \"INSERT\"\n",
    "\n",
    "2. **Streaming source:** `orderline_changes_stream`\n",
    "   * Read from `bronze_orderline_changes`\n",
    "\n",
    "3. **Apply CDC:**\n",
    "   * Target: `silver_order_lines`\n",
    "   * Composite keys: `[\"order_id\", \"line_number\"]`\n",
    "   * Sequence by: `change_timestamp`\n",
    "   * SCD Type 1\n",
    "   * Handle deletes: `operation = 'DELETE'`\n",
    "   * Exclude columns: `[\"operation\"]`\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code below:** üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dd03f8b-d21b-4751-a30e-649e10ea0191",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Challenge 3 Solution Space"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CHALLENGE 3: Your solution here\n",
    "# ============================================\n",
    "\n",
    "# TODO: Create bronze_orderline_changes table\n",
    "\n",
    "\n",
    "# TODO: Create orderline_changes_stream table\n",
    "\n",
    "\n",
    "# TODO: Apply CDC with composite keys and delete handling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b88d6870-568f-4bd1-985b-c9bf8baddc98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Part 6: Best Practices and Monitoring ‚úÖ\n",
    "\n",
    "Let's cover best practices for production Auto CDC pipelines.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "258c9ef4-1638-4445-9aca-4ccd8ea6ccc0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Best Practices"
    }
   },
   "source": [
    "%undefined\n",
    "### üéØ Auto CDC Best Practices\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Choose the Right SCD Type**\n",
    "\n",
    "**SCD Type 1 (Overwrite):**\n",
    "* ‚úÖ Use when: History not needed\n",
    "* ‚úÖ Use when: Storage is a concern\n",
    "* ‚úÖ Use when: Only current state matters\n",
    "* ‚úÖ Examples: Reference data, dimension corrections\n",
    "\n",
    "**SCD Type 2 (History):**\n",
    "* ‚úÖ Use when: Audit trail required\n",
    "* ‚úÖ Use when: Compliance needs\n",
    "* ‚úÖ Use when: Historical analysis needed\n",
    "* ‚úÖ Examples: Customer data, pricing, product attributes\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Sequence Column Selection**\n",
    "\n",
    "**Good sequence columns:**\n",
    "* ‚úÖ Timestamp with high precision\n",
    "* ‚úÖ Monotonically increasing version number\n",
    "* ‚úÖ Transaction ID or log sequence number\n",
    "\n",
    "**Bad sequence columns:**\n",
    "* ‚ùå Date only (no time)\n",
    "* ‚ùå Non-unique values\n",
    "* ‚ùå Can decrease or reset\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Good\n",
    "sequence_by=col(\"updated_timestamp\")  # Timestamp with milliseconds\n",
    "sequence_by=col(\"version_number\")     # Incrementing integer\n",
    "\n",
    "# Bad\n",
    "sequence_by=col(\"updated_date\")       # Date only, multiple changes per day\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Primary Key Selection**\n",
    "\n",
    "**Requirements:**\n",
    "* ‚úÖ Must be unique\n",
    "* ‚úÖ Must be immutable (never changes)\n",
    "* ‚úÖ Must be present in all records\n",
    "* ‚úÖ Should be business meaningful\n",
    "\n",
    "**Examples:**\n",
    "```python\n",
    "# Good\n",
    "keys=[\"customer_id\"]                    # Natural key\n",
    "keys=[\"order_id\", \"line_number\"]        # Composite key\n",
    "\n",
    "# Avoid if possible\n",
    "keys=[\"surrogate_key\"]                  # Generated key (less meaningful)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Handle Out-of-Order Data**\n",
    "\n",
    "Auto CDC automatically handles out-of-order data using `sequence_by`:\n",
    "\n",
    "```python\n",
    "# Changes arrive out of order:\n",
    "Timestamp | customer_id | email\n",
    "10:05     | 1           | new@email.com\n",
    "10:00     | 1           | old@email.com   ‚Üê Arrives late\n",
    "\n",
    "# Auto CDC applies in correct order:\n",
    "# 1. old@email.com (10:00)\n",
    "# 2. new@email.com (10:05)\n",
    "```\n",
    "\n",
    "**Best practice:** Always specify `sequence_by` for reliable ordering.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Data Quality with Expectations**\n",
    "\n",
    "Combine Auto CDC with expectations:\n",
    "\n",
    "```python\n",
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "@dp.view(\n",
    "    expect_or_drop={\n",
    "        \"valid_key\": \"customer_id IS NOT NULL\",\n",
    "        \"valid_sequence\": \"change_timestamp IS NOT NULL\"\n",
    "    }\n",
    ")\n",
    "def customer_changes_validated():\n",
    "    return spark.readStream.table(\"bronze_customer_changes\")\n",
    "\n",
    "dp.create_streaming_table(\"silver_customers\")\n",
    "\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_customers\",\n",
    "    source=\"customer_changes_validated\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"change_timestamp\")\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Performance Optimization**\n",
    "\n",
    "**Partition target tables:**\n",
    "```python\n",
    "@dp.table(\n",
    "    partition_cols=[\"change_date\"],\n",
    "    table_properties={\n",
    "        \"delta.autoOptimize.optimizeWrite\": \"true\",\n",
    "        \"delta.autoOptimize.autoCompact\": \"true\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "**Use appropriate cluster size:**\n",
    "* Start small for development\n",
    "* Scale up for production based on data volume\n",
    "\n",
    "**Monitor pipeline metrics:**\n",
    "* Check processing latency\n",
    "* Monitor backlog size\n",
    "* Track error rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c0f01ce-bea6-4041-a258-f5c14c70486d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üìä Monitoring Auto CDC Pipelines\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Pipeline Event Log**\n",
    "\n",
    "View CDC operations in the event log:\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    timestamp,\n",
    "    details:flow_definition.output_dataset as target_table,\n",
    "    details:flow_definition.input_datasets as source_tables,\n",
    "    details:flow_progress.metrics\n",
    "FROM event_log(TABLE(silver_customers))\n",
    "WHERE event_type = 'flow_progress'\n",
    "ORDER BY timestamp DESC\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Check SCD Type 2 History**\n",
    "\n",
    "**Count versions per key:**\n",
    "```sql\n",
    "SELECT \n",
    "    customer_id,\n",
    "    COUNT(*) as version_count,\n",
    "    MIN(__START_AT) as first_seen,\n",
    "    MAX(__START_AT) as last_changed\n",
    "FROM silver_customers_history\n",
    "GROUP BY customer_id\n",
    "ORDER BY version_count DESC\n",
    "```\n",
    "\n",
    "**Find current records:**\n",
    "```sql\n",
    "SELECT COUNT(*) as current_records\n",
    "FROM silver_customers_history\n",
    "WHERE __CURRENT = true\n",
    "```\n",
    "\n",
    "**Find deleted records:**\n",
    "```sql\n",
    "SELECT *\n",
    "FROM silver_customers_history\n",
    "WHERE __CURRENT = false\n",
    "  AND __END_AT IS NOT NULL\n",
    "ORDER BY __END_AT DESC\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Validate CDC Processing**\n",
    "\n",
    "**Compare source and target counts:**\n",
    "```sql\n",
    "-- Source changes\n",
    "SELECT COUNT(*) as source_count\n",
    "FROM bronze_customer_changes\n",
    "\n",
    "-- Target records (current only for SCD Type 2)\n",
    "SELECT COUNT(*) as target_count\n",
    "FROM silver_customers_history\n",
    "WHERE __CURRENT = true\n",
    "```\n",
    "\n",
    "**Check for duplicates:**\n",
    "```sql\n",
    "SELECT \n",
    "    customer_id,\n",
    "    COUNT(*) as duplicate_count\n",
    "FROM silver_customers_history\n",
    "WHERE __CURRENT = true\n",
    "GROUP BY customer_id\n",
    "HAVING COUNT(*) > 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Common Issues and Solutions**\n",
    "\n",
    "**Issue: Duplicate keys in target**\n",
    "* **Cause:** Multiple records with same key and `__CURRENT = true`\n",
    "* **Solution:** Check `sequence_by` column has unique values per key\n",
    "\n",
    "**Issue: Missing records**\n",
    "* **Cause:** Records filtered out or failed expectations\n",
    "* **Solution:** Check expectations and source data quality\n",
    "\n",
    "**Issue: Out-of-order processing**\n",
    "* **Cause:** `sequence_by` column not properly ordered\n",
    "* **Solution:** Use timestamp with high precision or version number\n",
    "\n",
    "**Issue: Slow processing**\n",
    "* **Cause:** Large backlog or insufficient resources\n",
    "* **Solution:** Scale up cluster, optimize source queries, add partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "882c92b0-c0f9-4bef-90bb-e45741c05499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### üèÜ Complete Production-Ready Example\n",
    "\n",
    "Here's a complete Auto CDC pipeline with all best practices:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc8e5f41-c4e3-42a1-a34b-d54ac09b52ff",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Production Example Code"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PRODUCTION-READY AUTO CDC PIPELINE\n",
    "# ============================================\n",
    "\n",
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# ============================================\n",
    "# BRONZE: Ingest with data quality checks\n",
    "# ============================================\n",
    "\n",
    "@dp.table(\n",
    "    name=\"bronze_customer_changes_prod\",\n",
    "    comment=\"Production customer CDC feed with quality checks\",\n",
    "    expect={\n",
    "        \"valid_timestamp\": \"change_timestamp IS NOT NULL\",\n",
    "        \"valid_operation\": \"operation IN ('INSERT', 'UPDATE', 'DELETE')\"\n",
    "    }\n",
    ")\n",
    "def bronze_customer_changes_prod():\n",
    "    \"\"\"\n",
    "    Ingest customer changes with monitoring.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.readStream\n",
    "        .table(\"samples.tpch.customer\")\n",
    "        .select(\n",
    "            col(\"c_custkey\").alias(\"customer_id\"),\n",
    "            col(\"c_name\").alias(\"customer_name\"),\n",
    "            col(\"c_address\").alias(\"address\"),\n",
    "            col(\"c_phone\").alias(\"phone\"),\n",
    "            col(\"c_mktsegment\").alias(\"market_segment\"),\n",
    "            col(\"c_acctbal\").alias(\"account_balance\"),\n",
    "            current_timestamp().alias(\"change_timestamp\"),\n",
    "            lit(\"INSERT\").alias(\"operation\"),\n",
    "            lit(\"tpch_source\").alias(\"source_system\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# ============================================\n",
    "# SILVER: Validated view for CDC\n",
    "# ============================================\n",
    "\n",
    "@dp.view(\n",
    "    name=\"customer_changes_validated\",\n",
    "    comment=\"Validated customer changes ready for CDC\",\n",
    "    expect_or_drop={\n",
    "        \"valid_key\": \"customer_id IS NOT NULL\",\n",
    "        \"valid_sequence\": \"change_timestamp IS NOT NULL\",\n",
    "        \"valid_name\": \"customer_name IS NOT NULL AND LENGTH(customer_name) > 0\"\n",
    "    }\n",
    ")\n",
    "def customer_changes_validated():\n",
    "    \"\"\"\n",
    "    Validate and clean changes before CDC processing.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.readStream.table(\"bronze_customer_changes_prod\")\n",
    "        .filter(col(\"operation\").isin([\"INSERT\", \"UPDATE\", \"DELETE\"]))\n",
    "    )\n",
    "\n",
    "# ============================================\n",
    "# SILVER: Apply CDC with SCD Type 2\n",
    "# ============================================\n",
    "\n",
    "# Create target streaming table\n",
    "dp.create_streaming_table(\"silver_customers_prod\")\n",
    "\n",
    "# Create Auto CDC flow with advanced features\n",
    "dp.create_auto_cdc_flow(\n",
    "    target=\"silver_customers_prod\",\n",
    "    source=\"customer_changes_validated\",\n",
    "    keys=[\"customer_id\"],\n",
    "    sequence_by=col(\"change_timestamp\"),\n",
    "    stored_as_scd_type=\"2\",\n",
    "    apply_as_deletes=expr(\"operation = 'DELETE'\"),\n",
    "    except_column_list=[\"operation\", \"source_system\"],  # Exclude metadata\n",
    "    track_history_except_column_list=[\"account_balance\"]  # Don't track history for this column\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75ff7f0e-3792-4ed5-93c9-16fc4fdb9c16",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Summary"
    }
   },
   "source": [
    "\n",
    "## Summary: Auto CDC Mastery üéì\n",
    "\n",
    "Congratulations! You've learned how to use the **new Auto CDC API** in Lakeflow pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts:**\n",
    "\n",
    "**1. CDC Basics:**\n",
    "* ‚úÖ Tracks INSERT, UPDATE, DELETE operations\n",
    "* ‚úÖ Maintains data history\n",
    "* ‚úÖ Essential for data warehousing\n",
    "\n",
    "**2. New Auto CDC API:**\n",
    "* ‚úÖ Import: `from pyspark import pipelines as dp`\n",
    "* ‚úÖ Create target: `dp.create_streaming_table()`\n",
    "* ‚úÖ Create flow: `dp.create_auto_cdc_flow()`\n",
    "* ‚úÖ Automatic merge and deduplication\n",
    "* ‚úÖ Handles out-of-order data\n",
    "\n",
    "**3. SCD Types:**\n",
    "* ‚úÖ **Type 1:** Overwrite (no history) - `stored_as_scd_type=\"1\"`\n",
    "* ‚úÖ **Type 2:** Track history (audit trail) - `stored_as_scd_type=\"2\"`\n",
    "\n",
    "**4. Key Parameters:**\n",
    "* ‚úÖ `target` - Target table name (string)\n",
    "* ‚úÖ `source` - Source view name (string)\n",
    "* ‚úÖ `keys` - Primary key columns (list)\n",
    "* ‚úÖ `sequence_by` - Order changes (use `col()` function)\n",
    "* ‚úÖ `stored_as_scd_type` - \"1\" or \"2\" (string)\n",
    "* ‚úÖ `apply_as_deletes` - Handle deletes (use `expr()` function)\n",
    "* ‚úÖ `except_column_list` - Exclude columns from target\n",
    "* ‚úÖ `track_history_except_column_list` - Exclude from history tracking\n",
    "\n",
    "---\n",
    "\n",
    "### **Best Practices:**\n",
    "\n",
    "* ‚úÖ Choose appropriate SCD type\n",
    "* ‚úÖ Use reliable sequence column with `col()`\n",
    "* ‚úÖ Validate data with expectations\n",
    "* ‚úÖ Monitor pipeline metrics\n",
    "* ‚úÖ Handle deletes appropriately\n",
    "* ‚úÖ Use composite keys when needed\n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "1. **Create your pipeline:**\n",
    "   * Save this notebook\n",
    "   * Create Delta Live Tables pipeline\n",
    "   * Configure target catalog and schema\n",
    "\n",
    "2. **Run and monitor:**\n",
    "   * Start the pipeline\n",
    "   * Check event logs\n",
    "   * Validate CDC processing\n",
    "\n",
    "3. **Explore more:**\n",
    "   * Combine with expectations\n",
    "   * Add data quality rules\n",
    "   * Optimize performance\n",
    "\n",
    "---\n",
    "\n",
    "### **Resources:**\n",
    "\n",
    "* [Lakeflow Pipeline Fundamentals](#notebook/2846436383063456)\n",
    "* [Lakeflow Expectations](#notebook/2846436383063443)\n",
    "* [Databricks Auto CDC Documentation](https://docs.databricks.com/aws/en/ldp/cdc/)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy CDC processing!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20abf3ce-3d8c-493b-8c0d-7abcd436fa74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Creating Your Auto CDC Pipeline üõ†Ô∏è\n",
    "\n",
    "Follow these steps to create and run your pipeline:\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 1: Save This Notebook**\n",
    "\n",
    "1. Click **\"Save\"** or press `Ctrl+S`\n",
    "2. Note the notebook path\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Create Delta Live Tables Pipeline**\n",
    "\n",
    "1. Click **\"Workflows\"** in the left sidebar\n",
    "2. Click **\"Delta Live Tables\"** tab\n",
    "3. Click **\"Create Pipeline\"**\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Configure Pipeline**\n",
    "\n",
    "**General settings:**\n",
    "* **Pipeline name:** `auto_cdc_demo`\n",
    "* **Product edition:** Advanced (required for CDC)\n",
    "* **Notebook libraries:** Add this notebook\n",
    "\n",
    "**Destination:**\n",
    "* **Catalog:** Your catalog name\n",
    "* **Target schema:** `auto_cdc_demo`\n",
    "\n",
    "**Compute:**\n",
    "* **Pipeline mode:** Triggered (for learning)\n",
    "* **Cluster mode:** Enhanced autoscaling\n",
    "* **Min workers:** 1\n",
    "* **Max workers:** 2\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Start Pipeline**\n",
    "\n",
    "1. Click **\"Start\"**\n",
    "2. Watch the pipeline execute\n",
    "3. View the lineage graph\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 5: Explore Results**\n",
    "\n",
    "**Query SCD Type 1 table:**\n",
    "```sql\n",
    "SELECT * FROM <catalog>.auto_cdc_demo.silver_customers\n",
    "LIMIT 10\n",
    "```\n",
    "\n",
    "**Query SCD Type 2 table:**\n",
    "```sql\n",
    "-- Current records only\n",
    "SELECT * FROM <catalog>.auto_cdc_demo.silver_customers_history\n",
    "WHERE __CURRENT = true\n",
    "LIMIT 10\n",
    "\n",
    "-- All history\n",
    "SELECT * FROM <catalog>.auto_cdc_demo.silver_customers_history\n",
    "ORDER BY customer_id, __START_AT\n",
    "LIMIT 20\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**You're ready to build production CDC pipelines!** üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d999855-7119-40a8-bf2e-7601c49eaa33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Lakeflow Auto CDC",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
