{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8105b450-b583-4bf5-8669-4bbef26b36bc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Lab Title"
    }
   },
   "source": [
    "# Medallion Architecture Lab: Bronze ‚Üí Silver ‚Üí Gold ü•âü•àü•á\n",
    "\n",
    "Welcome to the Medallion Architecture lab! In this hands-on lab, you'll build a complete data pipeline using Databricks SQL.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. ‚úÖ Understand the medallion architecture (bronze, silver, gold)\n",
    "2. ‚úÖ Use **COPY INTO** to ingest raw data into bronze tables\n",
    "3. ‚úÖ Use **MERGE INTO** to clean and deduplicate data for silver tables\n",
    "4. ‚úÖ Create aggregated business metrics in gold tables\n",
    "5. ‚úÖ Build an end-to-end data pipeline using SQL\n",
    "6. ‚úÖ Apply data quality checks and transformations\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è What is Medallion Architecture?\n",
    "\n",
    "The **Medallion Architecture** organizes data into three layers:\n",
    "\n",
    "### **ü•â Bronze Layer (Raw)**\n",
    "* **Purpose:** Ingest raw data (as-is)\n",
    "* **Characteristics:** Minimal processing, append-only, full history\n",
    "* **Quality:** May have duplicates, nulls, bad data\n",
    "* **Method:** COPY INTO for incremental ingestion\n",
    "\n",
    "### **ü•à Silver Layer (Cleaned)**\n",
    "* **Purpose:** Clean, validate, and deduplicate\n",
    "* **Characteristics:** Business-ready, no duplicates, validated\n",
    "* **Quality:** High quality, consistent schema\n",
    "* **Method:** MERGE INTO for upserts and deduplication\n",
    "\n",
    "### **ü•á Gold Layer (Aggregated)**\n",
    "* **Purpose:** Business-level aggregations and metrics\n",
    "* **Characteristics:** Optimized for analytics, pre-aggregated\n",
    "* **Quality:** Report-ready, fast queries\n",
    "* **Method:** Aggregation queries, materialized views\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Lab Scenario: E-Commerce Orders\n",
    "\n",
    "You're building a data pipeline for an e-commerce company:\n",
    "\n",
    "**Raw data:** Order files arrive in cloud storage (CSV format)\n",
    "\n",
    "**Your pipeline:**\n",
    "1. **Bronze:** Ingest raw order files\n",
    "2. **Silver:** Clean data, remove duplicates, validate\n",
    "3. **Gold:** Create daily sales metrics for dashboards\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Lab Structure\n",
    "\n",
    "This lab has **10 tasks** to complete:\n",
    "\n",
    "**Setup (Tasks 1-2):**\n",
    "1. Create volumes and generate sample order files\n",
    "2. Explore the raw data\n",
    "\n",
    "**Bronze Layer (Tasks 3-4):**\n",
    "3. Create bronze table\n",
    "4. Use COPY INTO to ingest raw data\n",
    "\n",
    "**Silver Layer (Tasks 5-6):**\n",
    "5. Create silver table with data quality rules\n",
    "6. Use MERGE INTO to clean and deduplicate\n",
    "\n",
    "**Gold Layer (Tasks 7-8):**\n",
    "7. Create gold table with daily metrics\n",
    "8. Build aggregation query\n",
    "\n",
    "**Validation (Tasks 9-10):**\n",
    "9. Verify data quality across layers\n",
    "10. Test incremental updates\n",
    "\n",
    "**Each task includes:**\n",
    "* üìù Clear instructions\n",
    "* üí° Hints to guide you\n",
    "* ‚úÖ Solutions at the end (try first!)\n",
    "\n",
    "---\n",
    "\n",
    "**Let's get started!** üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dfe65eb-17d9-4aae-81da-5301aa455bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 1: Setup - Create Volume and Generate Raw Data üõ†Ô∏è\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Create a Unity Catalog volume and generate sample order files to simulate raw data arriving from an e-commerce system.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "**Part A: Create Volume**\n",
    "1. Create a volume: `main.default.ecommerce_raw_data`\n",
    "2. This will store your raw CSV files\n",
    "\n",
    "**Part B: Generate Sample Order Files**\n",
    "1. Create 2 batches of order data (simulating data arriving at different times)\n",
    "2. Each batch should be a CSV file with these columns:\n",
    "   * `order_id` - INT\n",
    "   * `customer_id` - INT\n",
    "   * `order_date` - STRING (YYYY-MM-DD format)\n",
    "   * `product_name` - STRING\n",
    "   * `quantity` - INT\n",
    "   * `unit_price` - DOUBLE\n",
    "   * `status` - STRING ('completed', 'pending', 'cancelled')\n",
    "\n",
    "**Batch 1:** 100 orders (order_id 1-100)  \n",
    "**Batch 2:** 50 orders (order_id 101-150), **including 5 duplicates** from Batch 1 (order_id 1-5)\n",
    "\n",
    "**Data quality issues to include:**\n",
    "* Some null values in product_name\n",
    "* Some negative quantities (data errors)\n",
    "* Duplicates in Batch 2\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc987c81-ae32-4a59-8c39-88c43ae1106d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Setup"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create volume and generate 2 batches of CSV files\n",
    "# Batch 1: 100 orders\n",
    "# Batch 2: 50 orders + 5 duplicates from Batch 1\n",
    "# Include data quality issues (nulls, negatives, duplicates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87a2a0b6-6742-4fb1-a0da-5dc83a0fe031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 1\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> Create volume (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "spark.sql(\"\"\"\n",
    "  CREATE VOLUME IF NOT EXISTS main.default.ecommerce_raw_data\n",
    "  COMMENT 'Raw order files for medallion architecture lab'\n",
    "\"\"\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> Generate sample data (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "products = ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones', None]  # Include None for nulls\n",
    "statuses = ['completed', 'pending', 'cancelled']\n",
    "\n",
    "data_batch1 = [\n",
    "    (i, \n",
    "     random.randint(1, 50),\n",
    "     (datetime(2024, 1, 1) + timedelta(days=random.randint(0, 30))).strftime(\"%Y-%m-%d\"),\n",
    "     random.choice(products),\n",
    "     random.randint(-2, 10),  # Include negative for errors\n",
    "     round(random.uniform(10, 500), 2),\n",
    "     random.choice(statuses))\n",
    "    for i in range(1, 101)\n",
    "]\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 3:</b> Write CSV files (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType()),\n",
    "    StructField(\"customer_id\", IntegerType()),\n",
    "    StructField(\"order_date\", StringType()),\n",
    "    StructField(\"product_name\", StringType()),\n",
    "    StructField(\"quantity\", IntegerType()),\n",
    "    StructField(\"unit_price\", DoubleType()),\n",
    "    StructField(\"status\", StringType())\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/main/default/ecommerce_raw_data/batch1\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 4:</b> Create duplicates in Batch 2 (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Batch 2: New orders + duplicates from Batch 1\n",
    "data_batch2 = data_batch1[0:5]  # First 5 orders (duplicates)\n",
    "data_batch2 += [(i, ...) for i in range(101, 151)]  # New orders\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cab08d12-0489-45a1-960b-c53426424a0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 2: Explore the Raw Data üîç\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Examine the raw CSV files you created to understand the data quality issues.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Use `read_files()` to query the CSV files directly\n",
    "2. Look for:\n",
    "   * Null values in product_name\n",
    "   * Negative quantities\n",
    "   * Duplicate order_ids (between batch1 and batch2)\n",
    "3. Count total rows across both batches\n",
    "\n",
    "**Questions to answer:**\n",
    "* How many total rows are in the raw files?\n",
    "* How many rows have null product_name?\n",
    "* How many rows have negative quantity?\n",
    "* Are there duplicate order_ids?\n",
    "\n",
    "**Syntax:**\n",
    "```sql\n",
    "SELECT * FROM read_files(\n",
    "  '/Volumes/main/default/ecommerce_raw_data/',\n",
    "  format => 'csv',\n",
    "  header => true\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cf45617-32b9-4895-b799-a7a9cf9c1758",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Explore Raw Data"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Use read_files() to explore the raw CSV data\n",
    "-- Check for nulls, negatives, and duplicates\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cfc052b-605c-4b2f-a57f-703849c19850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 2\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> Read all CSV files (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "SELECT * \n",
    "FROM read_files(\n",
    "  '/Volumes/main/default/ecommerce_raw_data/',\n",
    "  format => 'csv',\n",
    "  header => true\n",
    ")\n",
    "LIMIT 20\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> Count data quality issues (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(CASE WHEN product_name IS NULL THEN 1 END) AS null_products,\n",
    "  COUNT(CASE WHEN quantity < 0 THEN 1 END) AS negative_quantities\n",
    "FROM read_files(\n",
    "  '/Volumes/main/default/ecommerce_raw_data/',\n",
    "  format => 'csv',\n",
    "  header => true\n",
    ")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 3:</b> Find duplicates (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  order_id,\n",
    "  COUNT(*) AS occurrence_count\n",
    "FROM read_files(\n",
    "  '/Volumes/main/default/ecommerce_raw_data/',\n",
    "  format => 'csv',\n",
    "  header => true\n",
    ")\n",
    "GROUP BY order_id\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY order_id\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a64271a-3286-4b94-ae40-1481aa00f186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ü•â Bronze Layer: Raw Data Ingestion\n",
    "\n",
    "The bronze layer stores raw data exactly as it arrives - no cleaning, no transformations.\n",
    "\n",
    "**Characteristics:**\n",
    "* Append-only (keep all data)\n",
    "* Minimal processing\n",
    "* May contain duplicates and errors\n",
    "* Full audit trail\n",
    "* Uses COPY INTO for incremental loading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42a9bcda-8b66-4501-ab32-59d5a01898d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 3: Create Bronze Table ü•â\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Create a Delta table for the bronze layer.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Table name: `main.default.orders_bronze`\n",
    "2. Columns (match the CSV structure):\n",
    "   * `order_id` INT\n",
    "   * `customer_id` INT\n",
    "   * `order_date` STRING (we'll convert to DATE in silver)\n",
    "   * `product_name` STRING\n",
    "   * `quantity` INT\n",
    "   * `unit_price` DOUBLE\n",
    "   * `status` STRING\n",
    "   * `ingestion_timestamp` TIMESTAMP (add this for tracking)\n",
    "3. Use Delta format\n",
    "4. Add a comment describing the table\n",
    "\n",
    "**Bronze layer principle:** Store raw data as-is, add metadata columns for tracking.\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec34ebba-dec8-413e-91e9-c8e346b3729c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Create Bronze Table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Create the bronze table\n",
    "-- Include all columns from CSV plus ingestion_timestamp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dfb6d4d3-962a-4f43-b7d7-4c5f5b1bdbf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 3\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> CREATE TABLE syntax (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS main.default.orders_bronze (\n",
    "  column_name data_type,\n",
    "  ...\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'description'\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> All columns needed (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "order_id INT,\n",
    "customer_id INT,\n",
    "order_date STRING,\n",
    "product_name STRING,\n",
    "quantity INT,\n",
    "unit_price DOUBLE,\n",
    "status STRING,\n",
    "ingestion_timestamp TIMESTAMP\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 3:</b> Why STRING for order_date? (click to expand)</summary>\n",
    "\n",
    "In bronze, we keep data as-is from the source.\n",
    "* Source has dates as strings\n",
    "* We'll convert to proper DATE type in silver layer\n",
    "* This preserves raw data exactly as received\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99d5cb57-b2ac-41d1-95a1-ab8a903c32c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 4: Ingest Data with COPY INTO üì•\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Use COPY INTO to incrementally load data from CSV files into the bronze table.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "**Part A: Load Batch 1**\n",
    "1. Use COPY INTO to load from `/Volumes/main/default/ecommerce_raw_data/batch1/`\n",
    "2. Set FORMAT_OPTIONS for CSV (header = true)\n",
    "3. The ingestion_timestamp should be set to CURRENT_TIMESTAMP()\n",
    "\n",
    "**Part B: Load Batch 2**\n",
    "1. Run COPY INTO again for batch2\n",
    "2. Verify it only loads new files (idempotency)\n",
    "3. Check total row count\n",
    "\n",
    "**Expected results:**\n",
    "* After Batch 1: 100 rows\n",
    "* After Batch 2: 155 rows (100 + 50 + 5 duplicates)\n",
    "\n",
    "**COPY INTO syntax:**\n",
    "```sql\n",
    "COPY INTO target_table\n",
    "FROM 'source_path'\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cells below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b11a8eb6-9d9b-4b21-9f8a-c248adf5b448",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Load Batch 1"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Use COPY INTO to load batch1\n",
    "-- Don't forget to set ingestion_timestamp to CURRENT_TIMESTAMP()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b87e7a59-a478-49fc-aa4d-eefae38a20f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Load Batch 2"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Use COPY INTO to load batch2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b13b4e4-6eeb-450a-9dae-b36099546983",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Verify Bronze Data"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Check the bronze table\n",
    "-- Count total rows, check for duplicates and data quality issues\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac40b391-eacf-48eb-af4f-2a5d70d2a539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 4\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> COPY INTO with column mapping (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "COPY INTO main.default.orders_bronze\n",
    "FROM (\n",
    "  SELECT \n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS ingestion_timestamp\n",
    "  FROM '/Volumes/main/default/ecommerce_raw_data/batch1/'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'true')\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> Load batch2 (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "COPY INTO main.default.orders_bronze\n",
    "FROM (\n",
    "  SELECT \n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS ingestion_timestamp\n",
    "  FROM '/Volumes/main/default/ecommerce_raw_data/batch2/'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'true')\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 3:</b> Verify data (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "-- Count total rows\n",
    "SELECT COUNT(*) AS total_rows FROM main.default.orders_bronze\n",
    "\n",
    "-- Check for issues\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(DISTINCT order_id) AS unique_orders,\n",
    "  COUNT(*) - COUNT(DISTINCT order_id) AS duplicate_count,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products,\n",
    "  SUM(CASE WHEN quantity < 0 THEN 1 ELSE 0 END) AS negative_quantities\n",
    "FROM main.default.orders_bronze\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "666dfa9f-e307-4f41-a6b3-5c21965e39bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ü•à Silver Layer: Cleaned & Validated Data\n",
    "\n",
    "The silver layer contains cleaned, validated, and deduplicated data ready for business use.\n",
    "\n",
    "**Transformations:**\n",
    "* Remove duplicates (keep latest version)\n",
    "* Filter out invalid data (nulls, negatives)\n",
    "* Convert data types (STRING ‚Üí DATE)\n",
    "* Add calculated columns (total_amount)\n",
    "* Enforce data quality rules\n",
    "\n",
    "**Method:** MERGE INTO for upserts and deduplication\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5aa5a94-d58d-423e-b802-b3782f436cee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 5: Create Silver Table ü•à\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Create a cleaned version of the orders table with proper data types and calculated columns.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Table name: `main.default.orders_silver`\n",
    "2. Columns:\n",
    "   * `order_id` INT (primary key)\n",
    "   * `customer_id` INT\n",
    "   * `order_date` DATE (converted from STRING)\n",
    "   * `product_name` STRING\n",
    "   * `quantity` INT\n",
    "   * `unit_price` DOUBLE\n",
    "   * `total_amount` DOUBLE (calculated: quantity * unit_price)\n",
    "   * `status` STRING\n",
    "   * `created_at` TIMESTAMP (when first inserted)\n",
    "   * `updated_at` TIMESTAMP (when last updated)\n",
    "3. Use Delta format\n",
    "4. Add comment: 'Cleaned and validated orders - Silver layer'\n",
    "\n",
    "**Key differences from bronze:**\n",
    "* order_date is DATE (not STRING)\n",
    "* Added total_amount (calculated column)\n",
    "* Added created_at and updated_at for tracking\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9801692-5435-4081-a35e-f3e2119d2427",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Create Silver Table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Create the silver table with proper data types\n",
    "-- Include calculated column (total_amount)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4137a904-1eb0-4b34-b0b7-be0b3e2b5976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 5\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> Complete CREATE TABLE (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS main.default.orders_silver (\n",
    "  order_id INT,\n",
    "  customer_id INT,\n",
    "  order_date DATE,\n",
    "  product_name STRING,\n",
    "  quantity INT,\n",
    "  unit_price DOUBLE,\n",
    "  total_amount DOUBLE,\n",
    "  status STRING,\n",
    "  created_at TIMESTAMP,\n",
    "  updated_at TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'Cleaned and validated orders - Silver layer'\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> Why these columns? (click to expand)</summary>\n",
    "\n",
    "* `order_date DATE` - Proper type for date operations\n",
    "* `total_amount` - Pre-calculated for performance\n",
    "* `created_at` - Track when order first appeared\n",
    "* `updated_at` - Track when order was last modified\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6652bc2c-ced1-4ec3-ab87-8a93c1623f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 6: Clean and Load Silver with MERGE INTO ‚ú®\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Use MERGE INTO to load cleaned data from bronze to silver.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "**Data Quality Rules:**\n",
    "1. **Remove duplicates** - Keep only one row per order_id (latest by ingestion_timestamp)\n",
    "2. **Filter out invalid data:**\n",
    "   * Skip rows where product_name IS NULL\n",
    "   * Skip rows where quantity <= 0\n",
    "   * Skip rows where unit_price <= 0\n",
    "3. **Transform data:**\n",
    "   * Convert order_date from STRING to DATE\n",
    "   * Calculate total_amount = quantity * unit_price\n",
    "4. **Use MERGE INTO:**\n",
    "   * WHEN MATCHED: Update existing orders\n",
    "   * WHEN NOT MATCHED: Insert new orders\n",
    "\n",
    "**Steps:**\n",
    "1. Create a CTE to clean and deduplicate bronze data\n",
    "2. Use MERGE INTO to upsert into silver\n",
    "3. Set created_at on INSERT, updated_at on both INSERT and UPDATE\n",
    "\n",
    "**Expected results:**\n",
    "* Should have ~145 rows (155 minus ~10 invalid rows)\n",
    "* No duplicates (order_id is unique)\n",
    "* All data quality rules applied\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9873596d-cd73-4ce3-bb70-b08d1286293a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: MERGE Bronze to Silver"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Create CTE to clean bronze data, then MERGE into silver\n",
    "-- Apply all data quality rules\n",
    "-- Handle duplicates (keep latest by ingestion_timestamp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c73455a9-e224-4d05-85d7-6c83fc0523b4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Verify Silver Data"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Verify silver table\n",
    "-- Check row count, no duplicates, no invalid data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdc867a1-62a4-4581-bc18-aa364e4e82bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 6\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> Clean and deduplicate CTE (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "WITH cleaned_orders AS (\n",
    "  SELECT \n",
    "    order_id,\n",
    "    customer_id,\n",
    "    CAST(order_date AS DATE) AS order_date,\n",
    "    product_name,\n",
    "    quantity,\n",
    "    unit_price,\n",
    "    quantity * unit_price AS total_amount,\n",
    "    status,\n",
    "    ingestion_timestamp,\n",
    "    ROW_NUMBER() OVER (PARTITION BY order_id ORDER BY ingestion_timestamp DESC) AS rn\n",
    "  FROM main.default.orders_bronze\n",
    "  WHERE product_name IS NOT NULL\n",
    "    AND quantity > 0\n",
    "    AND unit_price > 0\n",
    ")\n",
    "SELECT * FROM cleaned_orders WHERE rn = 1\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> MERGE INTO structure (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "MERGE INTO main.default.orders_silver AS target\n",
    "USING cleaned_orders AS source\n",
    "ON target.order_id = source.order_id\n",
    "\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.customer_id = source.customer_id,\n",
    "    ...,\n",
    "    target.updated_at = CURRENT_TIMESTAMP()\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (...)\n",
    "  VALUES (..., CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP())\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 3:</b> Complete solution structure (click to expand)</summary>\n",
    "\n",
    "You need:\n",
    "1. CTE to clean and deduplicate\n",
    "2. MERGE INTO with both WHEN MATCHED and WHEN NOT MATCHED\n",
    "3. Set created_at and updated_at appropriately\n",
    "4. Don't include the rn column in the MERGE\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "883c22a0-433a-4e7b-94e3-a221ad4c3de4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ü•á Gold Layer: Business Metrics\n",
    "\n",
    "The gold layer contains aggregated, business-ready data optimized for analytics and reporting.\n",
    "\n",
    "**Characteristics:**\n",
    "* Pre-aggregated metrics\n",
    "* Optimized for dashboards\n",
    "* Fast query performance\n",
    "* Business-friendly column names\n",
    "* Often materialized views or summary tables\n",
    "\n",
    "**Common patterns:**\n",
    "* Daily/monthly aggregations\n",
    "* Customer metrics\n",
    "* Product performance\n",
    "* KPIs and business metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6d80156-883e-414f-bf6e-4af6e34f18fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 7: Create Gold Table ü•á\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Create a gold table for daily sales metrics.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Table name: `main.default.daily_sales_gold`\n",
    "2. Columns:\n",
    "   * `order_date` DATE\n",
    "   * `total_orders` INT\n",
    "   * `total_revenue` DOUBLE\n",
    "   * `avg_order_value` DOUBLE\n",
    "   * `total_quantity_sold` INT\n",
    "   * `unique_customers` INT\n",
    "   * `completed_orders` INT\n",
    "   * `cancelled_orders` INT\n",
    "   * `updated_at` TIMESTAMP\n",
    "3. Use Delta format\n",
    "4. Add comment: 'Daily sales metrics - Gold layer'\n",
    "\n",
    "**This table will store one row per date with aggregated metrics.**\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "025bf136-3298-407e-a708-95c3bbad7f9b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Create Gold Table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Create the gold table for daily metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05735323-16e9-4c02-bd37-1af06ccb0a77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 7\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> CREATE TABLE syntax (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS main.default.daily_sales_gold (\n",
    "  order_date DATE,\n",
    "  total_orders INT,\n",
    "  total_revenue DOUBLE,\n",
    "  avg_order_value DOUBLE,\n",
    "  total_quantity_sold INT,\n",
    "  unique_customers INT,\n",
    "  completed_orders INT,\n",
    "  cancelled_orders INT,\n",
    "  updated_at TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'Daily sales metrics - Gold layer'\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> Why these metrics? (click to expand)</summary>\n",
    "\n",
    "These are common business metrics:\n",
    "* `total_orders` - Volume metric\n",
    "* `total_revenue` - Financial metric\n",
    "* `avg_order_value` - Performance metric\n",
    "* `unique_customers` - Customer metric\n",
    "* `completed_orders` / `cancelled_orders` - Status metrics\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6021dfc1-9d1e-404a-867c-2225b8ce24cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 8: Populate Gold Table with Aggregations üìà\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Write a query to calculate daily metrics from silver and insert into gold.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Query the silver table\n",
    "2. Group by order_date\n",
    "3. Calculate these metrics:\n",
    "   * `total_orders` - COUNT(*)\n",
    "   * `total_revenue` - SUM(total_amount)\n",
    "   * `avg_order_value` - AVG(total_amount)\n",
    "   * `total_quantity_sold` - SUM(quantity)\n",
    "   * `unique_customers` - COUNT(DISTINCT customer_id)\n",
    "   * `completed_orders` - COUNT where status = 'completed'\n",
    "   * `cancelled_orders` - COUNT where status = 'cancelled'\n",
    "4. Use INSERT OVERWRITE to populate the gold table\n",
    "5. Set updated_at to CURRENT_TIMESTAMP()\n",
    "\n",
    "**Hint:** Use CASE WHEN for conditional counts.\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6753bf3c-1d6e-456f-a8bb-81f8f3ea09a8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Populate Gold Table"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Write aggregation query and INSERT into gold table\n",
    "-- Group by order_date and calculate all metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49fca719-2dd4-45e9-a32a-01c8a678d910",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Verify Gold Data"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Query the gold table to see daily metrics\n",
    "-- Order by date to see trends\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39ae8add-f0c3-4f3b-ac8b-f8292610af98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 8\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> Aggregation query structure (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  order_date,\n",
    "  COUNT(*) AS total_orders,\n",
    "  SUM(total_amount) AS total_revenue,\n",
    "  AVG(total_amount) AS avg_order_value,\n",
    "  SUM(quantity) AS total_quantity_sold,\n",
    "  COUNT(DISTINCT customer_id) AS unique_customers,\n",
    "  SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) AS completed_orders,\n",
    "  SUM(CASE WHEN status = 'cancelled' THEN 1 ELSE 0 END) AS cancelled_orders,\n",
    "  CURRENT_TIMESTAMP() AS updated_at\n",
    "FROM main.default.orders_silver\n",
    "GROUP BY order_date\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> INSERT OVERWRITE (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "INSERT OVERWRITE main.default.daily_sales_gold\n",
    "SELECT \n",
    "  -- aggregation query here\n",
    "FROM main.default.orders_silver\n",
    "GROUP BY order_date\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 3:</b> Why INSERT OVERWRITE? (click to expand)</summary>\n",
    "\n",
    "For gold tables with full refresh:\n",
    "* INSERT OVERWRITE replaces all data\n",
    "* Recalculates all metrics from silver\n",
    "* Ensures consistency\n",
    "* Simple and reliable\n",
    "\n",
    "Alternatively, you could use MERGE INTO for incremental updates.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d1aa1f0-18e1-4597-8d47-b6b6fd866e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "\n",
    "# ‚úÖ Validation: Verify Your Pipeline\n",
    "\n",
    "Let's verify that your medallion architecture pipeline works correctly!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d70f7923-46ba-44a8-8608-9279da014617",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 9: Validate Data Quality Across Layers üîç\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Verify that data quality improves as it flows through the pipeline.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "Create a query that compares all three layers:\n",
    "\n",
    "1. **Bronze metrics:**\n",
    "   * Total rows\n",
    "   * Duplicate count\n",
    "   * Null product_name count\n",
    "   * Negative quantity count\n",
    "\n",
    "2. **Silver metrics:**\n",
    "   * Total rows (should be less than bronze)\n",
    "   * Duplicate count (should be 0)\n",
    "   * Null count (should be 0)\n",
    "   * Negative count (should be 0)\n",
    "\n",
    "3. **Gold metrics:**\n",
    "   * Total rows (number of unique dates)\n",
    "   * Total revenue sum\n",
    "\n",
    "**Expected results:**\n",
    "* Bronze: ~155 rows with issues\n",
    "* Silver: ~145 rows, clean\n",
    "* Gold: ~30 rows (one per date)\n",
    "\n",
    "**Use UNION ALL to combine metrics from all three layers.**\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87837105-c919-41d2-b102-24be55b4ccc9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Validate Data Quality"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Create a comparison query showing metrics from all three layers\n",
    "-- Use UNION ALL to combine results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d602010f-4f4d-4db6-a3d4-1f17de292bc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 9\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> Query structure (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  'Bronze' AS layer,\n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(*) - COUNT(DISTINCT order_id) AS duplicates,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products\n",
    "FROM main.default.orders_bronze\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Silver' AS layer,\n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(*) - COUNT(DISTINCT order_id) AS duplicates,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products\n",
    "FROM main.default.orders_silver\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Gold' AS layer,\n",
    "  COUNT(*) AS total_rows,\n",
    "  0 AS duplicates,\n",
    "  0 AS null_products\n",
    "FROM main.default.daily_sales_gold\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> What to verify (click to expand)</summary>\n",
    "\n",
    "**Bronze should have:**\n",
    "* More rows than silver\n",
    "* Duplicates present\n",
    "* Null values present\n",
    "* Negative quantities present\n",
    "\n",
    "**Silver should have:**\n",
    "* Fewer rows (invalid data removed)\n",
    "* No duplicates\n",
    "* No nulls\n",
    "* No negative values\n",
    "\n",
    "**Gold should have:**\n",
    "* Much fewer rows (aggregated by date)\n",
    "* Summary metrics only\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6228a5c7-315e-45dd-a3cf-fc274f9c7f7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Task 10: Test Incremental Updates üîÑ\n",
    "\n",
    "**Your Challenge:**\n",
    "\n",
    "Test that your pipeline handles new data correctly.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "**Part A: Add new raw data**\n",
    "1. Generate a 3rd batch of orders (order_id 151-200)\n",
    "2. Write to `/Volumes/main/default/ecommerce_raw_data/batch3/`\n",
    "\n",
    "**Part B: Run the pipeline**\n",
    "1. Use COPY INTO to load batch3 into bronze\n",
    "2. Use MERGE INTO to update silver\n",
    "3. Recalculate gold metrics\n",
    "\n",
    "**Part C: Verify**\n",
    "1. Check row counts increased appropriately\n",
    "2. Verify no duplicates in silver\n",
    "3. Verify gold metrics updated\n",
    "\n",
    "**This tests the end-to-end incremental processing!**\n",
    "\n",
    "---\n",
    "\n",
    "**Write your code in the cells below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2505023c-9852-4bc8-8325-694997332ced",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Generate Batch 3"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Generate batch 3 data (50 more orders, order_id 151-200)\n",
    "# Write to batch3 directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad701cfa-5889-4599-b852-b0dbe0a0446b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Load Batch 3 to Bronze"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Use COPY INTO to load batch3 into bronze\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2938ccf0-b90f-4f3d-8db9-19bf337a28d8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Update Silver"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Run your MERGE INTO query again to update silver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f8549ab-aa7c-405e-9bc8-df6d55e0cd91",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Update Gold"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Recalculate gold metrics (INSERT OVERWRITE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51204295-1b22-4545-b75a-6e5f0ae4d6db",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOUR CODE: Verify Final Counts"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- TODO: Check row counts in all three layers\n",
    "-- Bronze: should have ~205 rows\n",
    "-- Silver: should have ~195 rows\n",
    "-- Gold: should have ~30 rows (dates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "237b8b7d-40da-4df6-87ee-082cdb4af2b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üí° Hints for Task 10\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 1:</b> Generate batch 3 (click to expand)</summary>\n",
    "\n",
    "```python\n",
    "# Similar to Task 1, but different ID range\n",
    "data_batch3 = [\n",
    "    (i, \n",
    "     random.randint(1, 50),\n",
    "     (datetime(2024, 1, 1) + timedelta(days=random.randint(0, 30))).strftime(\"%Y-%m-%d\"),\n",
    "     random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones']),\n",
    "     random.randint(1, 10),\n",
    "     round(random.uniform(10, 500), 2),\n",
    "     random.choice(['completed', 'pending', 'cancelled']))\n",
    "    for i in range(151, 201)\n",
    "]\n",
    "\n",
    "df_batch3 = spark.createDataFrame(data_batch3, schema)\n",
    "df_batch3.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/main/default/ecommerce_raw_data/batch3\")\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 2:</b> Rerun the pipeline (click to expand)</summary>\n",
    "\n",
    "Just run the same commands again:\n",
    "1. COPY INTO for bronze (loads only batch3)\n",
    "2. MERGE INTO for silver (processes new bronze data)\n",
    "3. INSERT OVERWRITE for gold (recalculates all metrics)\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><b>Hint 3:</b> Verify counts (click to expand)</summary>\n",
    "\n",
    "```sql\n",
    "SELECT 'Bronze' AS layer, COUNT(*) AS row_count FROM main.default.orders_bronze\n",
    "UNION ALL\n",
    "SELECT 'Silver' AS layer, COUNT(*) AS row_count FROM main.default.orders_silver\n",
    "UNION ALL\n",
    "SELECT 'Gold' AS layer, COUNT(*) AS row_count FROM main.default.daily_sales_gold\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1de80c1-64a6-4568-9289-0caeb0f7b135",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "\n",
    "# üìù Complete Solutions\n",
    "\n",
    "**‚ö†Ô∏è Only look at these if you're stuck or want to verify your work!**\n",
    "\n",
    "Try to solve the challenges yourself first. Learning happens through problem-solving!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a1ed4cd-5747-4c9d-9f2d-a8660677f25d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 1 (Setup)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "```python\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "# Create volume\n",
    "spark.sql(\"\"\"\n",
    "  CREATE VOLUME IF NOT EXISTS main.default.ecommerce_raw_data\n",
    "  COMMENT 'Raw order files for medallion architecture lab'\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Volume created\")\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType()),\n",
    "    StructField(\"customer_id\", IntegerType()),\n",
    "    StructField(\"order_date\", StringType()),\n",
    "    StructField(\"product_name\", StringType()),\n",
    "    StructField(\"quantity\", IntegerType()),\n",
    "    StructField(\"unit_price\", DoubleType()),\n",
    "    StructField(\"status\", StringType())\n",
    "])\n",
    "\n",
    "products = ['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones', None]  # Include None\n",
    "statuses = ['completed', 'pending', 'cancelled']\n",
    "\n",
    "# Batch 1: 100 orders\n",
    "data_batch1 = [\n",
    "    (i, \n",
    "     random.randint(1, 50),\n",
    "     (datetime(2024, 1, 1) + timedelta(days=random.randint(0, 30))).strftime(\"%Y-%m-%d\"),\n",
    "     random.choice(products),\n",
    "     random.randint(-2, 10),  # Include negatives\n",
    "     round(random.uniform(10, 500), 2),\n",
    "     random.choice(statuses))\n",
    "    for i in range(1, 101)\n",
    "]\n",
    "\n",
    "df_batch1 = spark.createDataFrame(data_batch1, schema)\n",
    "df_batch1.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/main/default/ecommerce_raw_data/batch1\")\n",
    "print(\"‚úÖ Batch 1 created: 100 orders\")\n",
    "\n",
    "# Batch 2: 50 new orders + 5 duplicates\n",
    "data_batch2 = data_batch1[0:5]  # Duplicates\n",
    "data_batch2 += [\n",
    "    (i, \n",
    "     random.randint(1, 50),\n",
    "     (datetime(2024, 1, 1) + timedelta(days=random.randint(0, 30))).strftime(\"%Y-%m-%d\"),\n",
    "     random.choice(products),\n",
    "     random.randint(-2, 10),\n",
    "     round(random.uniform(10, 500), 2),\n",
    "     random.choice(statuses))\n",
    "    for i in range(101, 151)\n",
    "]\n",
    "\n",
    "df_batch2 = spark.createDataFrame(data_batch2, schema)\n",
    "df_batch2.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/main/default/ecommerce_raw_data/batch2\")\n",
    "print(\"‚úÖ Batch 2 created: 50 orders + 5 duplicates\")\n",
    "\n",
    "print(\"\\n‚úÖ Setup complete! Raw data files ready.\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8d563bb-ebc2-4014-9545-1a81fea96a04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 2 (Explore Raw Data)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "**View raw data:**\n",
    "```sql\n",
    "SELECT * \n",
    "FROM read_files(\n",
    "  '/Volumes/main/default/ecommerce_raw_data/',\n",
    "  format => 'csv',\n",
    "  header => true\n",
    ")\n",
    "LIMIT 20\n",
    "```\n",
    "\n",
    "**Check data quality issues:**\n",
    "```sql\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(DISTINCT order_id) AS unique_orders,\n",
    "  COUNT(*) - COUNT(DISTINCT order_id) AS duplicates,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products,\n",
    "  SUM(CASE WHEN CAST(quantity AS INT) < 0 THEN 1 ELSE 0 END) AS negative_quantities\n",
    "FROM read_files(\n",
    "  '/Volumes/main/default/ecommerce_raw_data/',\n",
    "  format => 'csv',\n",
    "  header => true\n",
    ")\n",
    "```\n",
    "\n",
    "**Find duplicate order_ids:**\n",
    "```sql\n",
    "SELECT \n",
    "  order_id,\n",
    "  COUNT(*) AS occurrence_count\n",
    "FROM read_files(\n",
    "  '/Volumes/main/default/ecommerce_raw_data/',\n",
    "  format => 'csv',\n",
    "  header => true\n",
    ")\n",
    "GROUP BY order_id\n",
    "HAVING COUNT(*) > 1\n",
    "ORDER BY order_id\n",
    "```\n",
    "\n",
    "**Expected findings:**\n",
    "* Total: 155 rows\n",
    "* Duplicates: 5 (order_id 1-5)\n",
    "* Nulls: ~10-15 rows\n",
    "* Negatives: ~10-15 rows\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "205cad86-f14a-4a3d-b868-6af9a4f31485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 3 (Create Bronze Table)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS main.default.orders_bronze (\n",
    "  order_id INT,\n",
    "  customer_id INT,\n",
    "  order_date STRING,\n",
    "  product_name STRING,\n",
    "  quantity INT,\n",
    "  unit_price DOUBLE,\n",
    "  status STRING,\n",
    "  ingestion_timestamp TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'Raw order data - Bronze layer'\n",
    "```\n",
    "\n",
    "**Key points:**\n",
    "* `order_date` is STRING (raw format from CSV)\n",
    "* Added `ingestion_timestamp` for tracking\n",
    "* Using DELTA format for ACID properties\n",
    "* IF NOT EXISTS prevents errors if table exists\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96b8cf9b-062a-457d-a976-ab3358a3b88e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 4 (Ingest with COPY INTO)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "**Load Batch 1:**\n",
    "```sql\n",
    "COPY INTO main.default.orders_bronze\n",
    "FROM (\n",
    "  SELECT \n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS ingestion_timestamp\n",
    "  FROM '/Volumes/main/default/ecommerce_raw_data/batch1/'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'true')\n",
    "```\n",
    "\n",
    "**Load Batch 2:**\n",
    "```sql\n",
    "COPY INTO main.default.orders_bronze\n",
    "FROM (\n",
    "  SELECT \n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS ingestion_timestamp\n",
    "  FROM '/Volumes/main/default/ecommerce_raw_data/batch2/'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'true')\n",
    "```\n",
    "\n",
    "**Verify:**\n",
    "```sql\n",
    "-- Check row count\n",
    "SELECT COUNT(*) AS total_rows FROM main.default.orders_bronze\n",
    "\n",
    "-- Check data quality\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(DISTINCT order_id) AS unique_orders,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products,\n",
    "  SUM(CASE WHEN quantity < 0 THEN 1 ELSE 0 END) AS negative_quantities\n",
    "FROM main.default.orders_bronze\n",
    "```\n",
    "\n",
    "**Key concepts:**\n",
    "* COPY INTO tracks processed files (idempotent)\n",
    "* Subquery adds ingestion_timestamp\n",
    "* inferSchema automatically detects types\n",
    "* Bronze contains ALL data (including bad data)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4968d89-7ea5-40e4-b227-6ec549eeaf4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 5 (Create Silver Table)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS main.default.orders_silver (\n",
    "  order_id INT,\n",
    "  customer_id INT,\n",
    "  order_date DATE,\n",
    "  product_name STRING,\n",
    "  quantity INT,\n",
    "  unit_price DOUBLE,\n",
    "  total_amount DOUBLE,\n",
    "  status STRING,\n",
    "  created_at TIMESTAMP,\n",
    "  updated_at TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'Cleaned and validated orders - Silver layer'\n",
    "```\n",
    "\n",
    "**Key differences from bronze:**\n",
    "* `order_date` is DATE (not STRING)\n",
    "* Added `total_amount` (calculated column)\n",
    "* Added `created_at` and `updated_at` for tracking\n",
    "* No ingestion_timestamp (that's bronze metadata)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c451d970-286b-4e79-9e61-a02e83b92a18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 6 (Clean and Load Silver)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "```sql\n",
    "MERGE INTO main.default.orders_silver AS target\n",
    "USING (\n",
    "  WITH cleaned_orders AS (\n",
    "    SELECT \n",
    "      order_id,\n",
    "      customer_id,\n",
    "      CAST(order_date AS DATE) AS order_date,\n",
    "      product_name,\n",
    "      quantity,\n",
    "      unit_price,\n",
    "      quantity * unit_price AS total_amount,\n",
    "      status,\n",
    "      ingestion_timestamp,\n",
    "      ROW_NUMBER() OVER (PARTITION BY order_id ORDER BY ingestion_timestamp DESC) AS rn\n",
    "    FROM main.default.orders_bronze\n",
    "    WHERE product_name IS NOT NULL\n",
    "      AND quantity > 0\n",
    "      AND unit_price > 0\n",
    "  )\n",
    "  SELECT \n",
    "    order_id,\n",
    "    customer_id,\n",
    "    order_date,\n",
    "    product_name,\n",
    "    quantity,\n",
    "    unit_price,\n",
    "    total_amount,\n",
    "    status\n",
    "  FROM cleaned_orders\n",
    "  WHERE rn = 1\n",
    ") AS source\n",
    "ON target.order_id = source.order_id\n",
    "\n",
    "WHEN MATCHED THEN\n",
    "  UPDATE SET\n",
    "    target.customer_id = source.customer_id,\n",
    "    target.order_date = source.order_date,\n",
    "    target.product_name = source.product_name,\n",
    "    target.quantity = source.quantity,\n",
    "    target.unit_price = source.unit_price,\n",
    "    target.total_amount = source.total_amount,\n",
    "    target.status = source.status,\n",
    "    target.updated_at = CURRENT_TIMESTAMP()\n",
    "\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (order_id, customer_id, order_date, product_name, quantity, unit_price, total_amount, status, created_at, updated_at)\n",
    "  VALUES (source.order_id, source.customer_id, source.order_date, source.product_name, source.quantity, source.unit_price, source.total_amount, source.status, CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP())\n",
    "```\n",
    "\n",
    "**Verify:**\n",
    "```sql\n",
    "SELECT \n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(DISTINCT order_id) AS unique_orders,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products,\n",
    "  SUM(CASE WHEN quantity <= 0 THEN 1 ELSE 0 END) AS invalid_quantities\n",
    "FROM main.default.orders_silver\n",
    "```\n",
    "\n",
    "**What this does:**\n",
    "1. CTE filters out invalid data (nulls, negatives)\n",
    "2. ROW_NUMBER deduplicates (keeps latest)\n",
    "3. CAST converts order_date to DATE\n",
    "4. Calculates total_amount\n",
    "5. MERGE upserts into silver\n",
    "6. Sets created_at on INSERT, updated_at on both\n",
    "\n",
    "**Expected results:**\n",
    "* ~145 rows (155 minus ~10 invalid)\n",
    "* 0 duplicates\n",
    "* 0 nulls\n",
    "* 0 negative quantities\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c604e17-707d-4adf-90e5-87b797d20374",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 7 (Create Gold Table)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "```sql\n",
    "CREATE TABLE IF NOT EXISTS main.default.daily_sales_gold (\n",
    "  order_date DATE,\n",
    "  total_orders INT,\n",
    "  total_revenue DOUBLE,\n",
    "  avg_order_value DOUBLE,\n",
    "  total_quantity_sold INT,\n",
    "  unique_customers INT,\n",
    "  completed_orders INT,\n",
    "  cancelled_orders INT,\n",
    "  updated_at TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'Daily sales metrics - Gold layer'\n",
    "```\n",
    "\n",
    "**Key points:**\n",
    "* One row per order_date\n",
    "* All metrics are aggregated\n",
    "* Business-friendly column names\n",
    "* Ready for dashboards and reports\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e35a158b-51a4-43e6-89f1-e65aefcafaa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 8 (Populate Gold Table)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "```sql\n",
    "INSERT OVERWRITE main.default.daily_sales_gold\n",
    "SELECT \n",
    "  order_date,\n",
    "  COUNT(*) AS total_orders,\n",
    "  ROUND(SUM(total_amount), 2) AS total_revenue,\n",
    "  ROUND(AVG(total_amount), 2) AS avg_order_value,\n",
    "  SUM(quantity) AS total_quantity_sold,\n",
    "  COUNT(DISTINCT customer_id) AS unique_customers,\n",
    "  SUM(CASE WHEN status = 'completed' THEN 1 ELSE 0 END) AS completed_orders,\n",
    "  SUM(CASE WHEN status = 'cancelled' THEN 1 ELSE 0 END) AS cancelled_orders,\n",
    "  CURRENT_TIMESTAMP() AS updated_at\n",
    "FROM main.default.orders_silver\n",
    "GROUP BY order_date\n",
    "ORDER BY order_date\n",
    "```\n",
    "\n",
    "**Verify:**\n",
    "```sql\n",
    "SELECT * \n",
    "FROM main.default.daily_sales_gold\n",
    "ORDER BY order_date\n",
    "```\n",
    "\n",
    "**What this does:**\n",
    "1. Groups by order_date\n",
    "2. Calculates all business metrics\n",
    "3. Uses CASE WHEN for conditional counts\n",
    "4. ROUND for clean numbers\n",
    "5. INSERT OVERWRITE replaces all data (full refresh)\n",
    "\n",
    "**Expected results:**\n",
    "* ~30 rows (one per unique date)\n",
    "* Each row has aggregated metrics for that day\n",
    "* Ready for dashboard visualization\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b48b472-543b-46df-b0e1-7ca575cb00ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 9 (Data Quality Validation)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "  'Bronze' AS layer,\n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(DISTINCT order_id) AS unique_orders,\n",
    "  COUNT(*) - COUNT(DISTINCT order_id) AS duplicates,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products,\n",
    "  SUM(CASE WHEN quantity < 0 THEN 1 ELSE 0 END) AS negative_quantities\n",
    "FROM main.default.orders_bronze\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Silver' AS layer,\n",
    "  COUNT(*) AS total_rows,\n",
    "  COUNT(DISTINCT order_id) AS unique_orders,\n",
    "  COUNT(*) - COUNT(DISTINCT order_id) AS duplicates,\n",
    "  SUM(CASE WHEN product_name IS NULL THEN 1 ELSE 0 END) AS null_products,\n",
    "  SUM(CASE WHEN quantity < 0 THEN 1 ELSE 0 END) AS negative_quantities\n",
    "FROM main.default.orders_silver\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Gold' AS layer,\n",
    "  COUNT(*) AS total_rows,\n",
    "  0 AS unique_orders,\n",
    "  0 AS duplicates,\n",
    "  0 AS null_products,\n",
    "  0 AS negative_quantities\n",
    "FROM main.default.daily_sales_gold\n",
    "\n",
    "ORDER BY layer\n",
    "```\n",
    "\n",
    "**Expected results:**\n",
    "\n",
    "| layer | total_rows | unique_orders | duplicates | null_products | negative_quantities |\n",
    "|-------|------------|---------------|------------|---------------|--------------------|\n",
    "| Bronze | 155 | 150 | 5 | ~10 | ~10 |\n",
    "| Silver | ~145 | ~145 | 0 | 0 | 0 |\n",
    "| Gold | ~30 | 0 | 0 | 0 | 0 |\n",
    "\n",
    "**Key insights:**\n",
    "* Bronze has all issues (duplicates, nulls, negatives)\n",
    "* Silver is clean (all issues removed)\n",
    "* Gold is aggregated (much fewer rows)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0639b52a-f28b-4766-b264-f58a61e16fdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ‚úÖ Solution: Task 10 (Test Incremental Updates)\n",
    "\n",
    "<details>\n",
    "<summary><b>Click to reveal solution</b></summary>\n",
    "\n",
    "**Generate Batch 3:**\n",
    "```python\n",
    "# Generate 50 more orders\n",
    "data_batch3 = [\n",
    "    (i, \n",
    "     random.randint(1, 50),\n",
    "     (datetime(2024, 1, 1) + timedelta(days=random.randint(0, 30))).strftime(\"%Y-%m-%d\"),\n",
    "     random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor', 'Headphones']),\n",
    "     random.randint(1, 10),\n",
    "     round(random.uniform(10, 500), 2),\n",
    "     random.choice(['completed', 'pending', 'cancelled']))\n",
    "    for i in range(151, 201)\n",
    "]\n",
    "\n",
    "df_batch3 = spark.createDataFrame(data_batch3, schema)\n",
    "df_batch3.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(\"/Volumes/main/default/ecommerce_raw_data/batch3\")\n",
    "print(\"‚úÖ Batch 3 created: 50 orders\")\n",
    "```\n",
    "\n",
    "**Load to Bronze:**\n",
    "```sql\n",
    "COPY INTO main.default.orders_bronze\n",
    "FROM (\n",
    "  SELECT \n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS ingestion_timestamp\n",
    "  FROM '/Volumes/main/default/ecommerce_raw_data/batch3/'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS ('header' = 'true', 'inferSchema' = 'true')\n",
    "```\n",
    "\n",
    "**Update Silver (rerun Task 6 MERGE):**\n",
    "```sql\n",
    "-- Same MERGE query from Task 6\n",
    "MERGE INTO main.default.orders_silver AS target\n",
    "USING (\n",
    "  -- Same cleaning logic\n",
    ") AS source\n",
    "ON target.order_id = source.order_id\n",
    "WHEN MATCHED THEN UPDATE SET ...\n",
    "WHEN NOT MATCHED THEN INSERT ...\n",
    "```\n",
    "\n",
    "**Update Gold (rerun Task 8):**\n",
    "```sql\n",
    "-- Same aggregation query from Task 8\n",
    "INSERT OVERWRITE main.default.daily_sales_gold\n",
    "SELECT \n",
    "  order_date,\n",
    "  COUNT(*) AS total_orders,\n",
    "  -- ... all metrics\n",
    "FROM main.default.orders_silver\n",
    "GROUP BY order_date\n",
    "```\n",
    "\n",
    "**Verify:**\n",
    "```sql\n",
    "SELECT \n",
    "  'Bronze' AS layer, \n",
    "  COUNT(*) AS row_count \n",
    "FROM main.default.orders_bronze\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Silver' AS layer, \n",
    "  COUNT(*) AS row_count \n",
    "FROM main.default.orders_silver\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Gold' AS layer, \n",
    "  COUNT(*) AS row_count \n",
    "FROM main.default.daily_sales_gold\n",
    "```\n",
    "\n",
    "**Expected results:**\n",
    "* Bronze: ~205 rows (155 + 50)\n",
    "* Silver: ~195 rows (cleaned)\n",
    "* Gold: ~30 rows (dates)\n",
    "\n",
    "**Key insight:** The pipeline is reusable - just rerun the same queries for new data!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "934b8d63-007d-4a24-ae30-0af357085639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üìö Medallion Architecture Best Practices\n",
    "\n",
    "### **ü•â Bronze Layer**\n",
    "\n",
    "‚úÖ **Keep raw data as-is** - No transformations  \n",
    "‚úÖ **Append-only** - Never delete from bronze  \n",
    "‚úÖ **Add metadata columns** - ingestion_timestamp, source_file  \n",
    "‚úÖ **Use COPY INTO** - Incremental, idempotent loading  \n",
    "‚úÖ **Partition by date** - If data has time dimension  \n",
    "\n",
    "**Purpose:** Audit trail, reprocessing capability, data lineage\n",
    "\n",
    "---\n",
    "\n",
    "### **ü•à Silver Layer**\n",
    "\n",
    "‚úÖ **Apply data quality rules** - Filter nulls, validate ranges  \n",
    "‚úÖ **Deduplicate** - One row per business key  \n",
    "‚úÖ **Convert data types** - STRING ‚Üí DATE, proper types  \n",
    "‚úÖ **Add calculated columns** - Derived values  \n",
    "‚úÖ **Use MERGE INTO** - Upserts, handle updates  \n",
    "‚úÖ **Track lineage** - created_at, updated_at  \n",
    "\n",
    "**Purpose:** Clean, validated data for analytics\n",
    "\n",
    "---\n",
    "\n",
    "### **ü•á Gold Layer**\n",
    "\n",
    "‚úÖ **Pre-aggregate** - Calculate metrics once  \n",
    "‚úÖ **Business-friendly** - Clear column names  \n",
    "‚úÖ **Optimize for queries** - Denormalize if needed  \n",
    "‚úÖ **Use INSERT OVERWRITE or MERGE** - Depends on pattern  \n",
    "‚úÖ **Document metrics** - What each column means  \n",
    "\n",
    "**Purpose:** Fast dashboards, reports, analytics\n",
    "\n",
    "---\n",
    "\n",
    "### **General Best Practices**\n",
    "\n",
    "‚úÖ **Separate concerns** - Each layer has clear purpose  \n",
    "‚úÖ **Idempotent pipelines** - Safe to rerun  \n",
    "‚úÖ **Incremental processing** - Process only new data  \n",
    "‚úÖ **Monitor data quality** - Track metrics at each layer  \n",
    "‚úÖ **Use Delta Lake** - ACID, time travel, performance  \n",
    "‚úÖ **Schedule appropriately** - Bronze (frequent), Silver (hourly), Gold (daily)  \n",
    "‚úÖ **Test with small data** - Validate logic before production  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75b2b6fe-d9f6-47dc-9bba-63bcc044b00b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üîÑ Common Pipeline Patterns\n",
    "\n",
    "### **Pattern 1: Batch Pipeline (This Lab)**\n",
    "\n",
    "```\n",
    "Raw Files ‚Üí Bronze (COPY INTO) ‚Üí Silver (MERGE) ‚Üí Gold (INSERT OVERWRITE)\n",
    "```\n",
    "\n",
    "**Schedule:**\n",
    "* Bronze: Every hour (ingest new files)\n",
    "* Silver: Every hour (clean new data)\n",
    "* Gold: Daily (aggregate for reports)\n",
    "\n",
    "---\n",
    "\n",
    "### **Pattern 2: Streaming Pipeline**\n",
    "\n",
    "```\n",
    "Raw Files ‚Üí Bronze (Auto Loader) ‚Üí Silver (Stream) ‚Üí Gold (Stream)\n",
    "```\n",
    "\n",
    "**Use when:**\n",
    "* Need real-time data\n",
    "* Continuous file arrival\n",
    "* Low latency requirements\n",
    "\n",
    "---\n",
    "\n",
    "### **Pattern 3: CDC Pipeline**\n",
    "\n",
    "```\n",
    "Change Data ‚Üí Bronze (COPY INTO) ‚Üí Silver (MERGE with SCD) ‚Üí Gold (Aggregations)\n",
    "```\n",
    "\n",
    "**Use when:**\n",
    "* Capturing database changes\n",
    "* Need historical tracking\n",
    "* SCD Type 2 requirements\n",
    "\n",
    "---\n",
    "\n",
    "### **Pattern 4: Multi-Source Pipeline**\n",
    "\n",
    "```\n",
    "Source A ‚Üí Bronze A ‚Üí\n",
    "                        ‚Üí Silver (JOIN) ‚Üí Gold\n",
    "Source B ‚Üí Bronze B ‚Üí\n",
    "```\n",
    "\n",
    "**Use when:**\n",
    "* Multiple data sources\n",
    "* Need to join data\n",
    "* Different ingestion schedules\n",
    "\n",
    "---\n",
    "\n",
    "### **This Lab's Pipeline**\n",
    "\n",
    "```\n",
    "CSV Files in Volume\n",
    "    ‚Üì\n",
    "    COPY INTO (incremental)\n",
    "    ‚Üì\n",
    "ü•â Bronze: orders_bronze (155 rows, raw data)\n",
    "    ‚Üì\n",
    "    MERGE INTO (clean, dedupe)\n",
    "    ‚Üì\n",
    "ü•à Silver: orders_silver (~145 rows, validated)\n",
    "    ‚Üì\n",
    "    INSERT OVERWRITE (aggregate)\n",
    "    ‚Üì\n",
    "ü•á Gold: daily_sales_gold (~30 rows, metrics)\n",
    "    ‚Üì\n",
    "    Dashboards & Reports\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "edd07527-aad2-4682-aacb-0858c538d64d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üí° Key Concepts Summary\n",
    "\n",
    "### **Medallion Architecture**\n",
    "\n",
    "**Bronze ‚Üí Silver ‚Üí Gold** = **Raw ‚Üí Cleaned ‚Üí Aggregated**\n",
    "\n",
    "**Why use it?**\n",
    "* Clear separation of concerns\n",
    "* Incremental processing\n",
    "* Data quality improvement\n",
    "* Reprocessing capability\n",
    "* Audit trail\n",
    "\n",
    "---\n",
    "\n",
    "### **COPY INTO (Bronze)**\n",
    "\n",
    "**Purpose:** Incremental file ingestion\n",
    "\n",
    "**Key features:**\n",
    "* Idempotent (safe to rerun)\n",
    "* Tracks processed files\n",
    "* SQL-based\n",
    "* Works in serverless\n",
    "\n",
    "**When to use:**\n",
    "* Loading files from cloud storage\n",
    "* Batch ingestion\n",
    "* Bronze layer ingestion\n",
    "\n",
    "---\n",
    "\n",
    "### **MERGE INTO (Silver)**\n",
    "\n",
    "**Purpose:** Upsert and deduplication\n",
    "\n",
    "**Key features:**\n",
    "* Atomic operation\n",
    "* Handles updates and inserts\n",
    "* No duplicates\n",
    "* Supports complex logic\n",
    "\n",
    "**When to use:**\n",
    "* Cleaning and validating data\n",
    "* Deduplication\n",
    "* SCD patterns\n",
    "* Silver layer updates\n",
    "\n",
    "---\n",
    "\n",
    "### **Aggregations (Gold)**\n",
    "\n",
    "**Purpose:** Business metrics\n",
    "\n",
    "**Key features:**\n",
    "* Pre-calculated metrics\n",
    "* Fast queries\n",
    "* Dashboard-ready\n",
    "* Business-friendly\n",
    "\n",
    "**When to use:**\n",
    "* Creating KPIs\n",
    "* Dashboard data\n",
    "* Report tables\n",
    "* Gold layer metrics\n",
    "\n",
    "---\n",
    "\n",
    "### **Data Quality**\n",
    "\n",
    "**Bronze:** Accept all data (good and bad)  \n",
    "**Silver:** Filter and validate  \n",
    "**Gold:** Aggregate clean data  \n",
    "\n",
    "**Quality improves at each layer!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75e0d40a-d387-4e33-b7d2-1724b12a0b16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üéâ Lab Complete!\n",
    "\n",
    "Congratulations! You've successfully built a complete medallion architecture pipeline!\n",
    "\n",
    "### **What You Accomplished:**\n",
    "\n",
    "‚úÖ **Created 3-layer architecture** - Bronze, Silver, Gold  \n",
    "‚úÖ **Used COPY INTO** - Incremental file ingestion  \n",
    "‚úÖ **Used MERGE INTO** - Data cleaning and deduplication  \n",
    "‚úÖ **Applied data quality rules** - Filtered invalid data  \n",
    "‚úÖ **Created business metrics** - Aggregated gold layer  \n",
    "‚úÖ **Tested incremental updates** - End-to-end pipeline  \n",
    "‚úÖ **Used Unity Catalog** - Modern data governance  \n",
    "‚úÖ **Pure SQL pipeline** - Works in serverless  \n",
    "\n",
    "---\n",
    "\n",
    "### **Your Pipeline:**\n",
    "\n",
    "```\n",
    "üìÅ Raw CSV Files (155 rows with issues)\n",
    "         ‚Üì\n",
    "      COPY INTO\n",
    "         ‚Üì\n",
    "ü•â Bronze Layer (155 rows, raw)\n",
    "         ‚Üì\n",
    "      MERGE INTO (clean, dedupe)\n",
    "         ‚Üì\n",
    "ü•à Silver Layer (~145 rows, validated)\n",
    "         ‚Üì\n",
    "      INSERT OVERWRITE (aggregate)\n",
    "         ‚Üì\n",
    "ü•á Gold Layer (~30 rows, metrics)\n",
    "         ‚Üì\n",
    "    üìä Dashboards\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Takeaways:**\n",
    "\n",
    "1. **Medallion architecture organizes data** - Clear layers with purpose\n",
    "2. **Bronze preserves raw data** - Full audit trail\n",
    "3. **Silver ensures quality** - Clean, validated, deduplicated\n",
    "4. **Gold optimizes for analytics** - Pre-aggregated metrics\n",
    "5. **COPY INTO for ingestion** - Incremental, idempotent\n",
    "6. **MERGE INTO for cleaning** - Upserts without duplicates\n",
    "7. **Each layer adds value** - Progressive refinement\n",
    "\n",
    "---\n",
    "\n",
    "### **Production Checklist:**\n",
    "\n",
    "‚òê Schedule bronze ingestion (hourly/daily)  \n",
    "‚òê Schedule silver processing (after bronze)  \n",
    "‚òê Schedule gold aggregation (daily)  \n",
    "‚òê Add data quality monitoring  \n",
    "‚òê Set up alerts for failures  \n",
    "‚òê Document data lineage  \n",
    "‚òê Implement error handling  \n",
    "‚òê Add data validation tests  \n",
    "\n",
    "---\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "* Build medallion pipelines for your data\n",
    "* Explore Delta Live Tables (DLT) for declarative pipelines\n",
    "* Add data quality expectations\n",
    "* Implement Change Data Capture (CDC)\n",
    "* Create dashboards from gold tables\n",
    "* Learn about data mesh architecture\n",
    "\n",
    "---\n",
    "\n",
    "### **Resources:**\n",
    "\n",
    "* [Medallion Architecture Guide](https://www.databricks.com/glossary/medallion-architecture)\n",
    "* [Delta Lake Best Practices](https://docs.databricks.com/delta/best-practices.html)\n",
    "* [COPY INTO Documentation](https://docs.databricks.com/sql/language-manual/delta-copy-into.html)\n",
    "* [MERGE INTO Documentation](https://docs.databricks.com/sql/language-manual/delta-merge-into.html)\n",
    "\n",
    "---\n",
    "\n",
    "**You're now ready to build production data pipelines!** üöÄ\n",
    "\n",
    "*Happy data engineering!*"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Medallion Architecture: SQL",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
